{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy==1.20.1\n",
    "!pip3 install pandas==1.2.3\n",
    "!pip3 install scipy==1.6.2\n",
    "!pip3 install statsmodels==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGtosNWZm7NZ",
    "outputId": "552348ed-a381-4e41-98dd-6a87c1f513c3"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "SYSTEMS_PATH = '../../results/ru'\n",
    "REFERENCES_PATH = '../../../references/references-ru.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkonoswLnGh1"
   },
   "source": [
    "# Parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N4aKdB4KnCau"
   },
   "outputs": [],
   "source": [
    "rdfs = json.load(open(REFERENCES_PATH))\n",
    "sys_files = [w for w in os.listdir(SYSTEMS_PATH) if not w.startswith('.') and not w.endswith('.json')]\n",
    "\n",
    "doc_id = 1\n",
    "data = []\n",
    "for sys_file in sys_files:\n",
    "    results = json.load(open(os.path.join(SYSTEMS_PATH, sys_file, 'primary.json')))\n",
    "    submission_id = sys_file\n",
    "\n",
    "    for sample_id in results:\n",
    "        entry = [w for w in rdfs['entries'] if list(w.keys())[0] == sample_id][0]\n",
    "        for worker_id in results[sample_id]:\n",
    "            assign = results[sample_id][worker_id]\n",
    "            inp = {\n",
    "                'id': doc_id,\n",
    "                'sample_id': sample_id,\n",
    "                'submission_id': submission_id,\n",
    "                'worker_id': worker_id,\n",
    "                'category': entry[sample_id]['category'],\n",
    "                'size': entry[sample_id]['size'],\n",
    "            }\n",
    "            inp.update(assign)\n",
    "            data.append(inp)\n",
    "            doc_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b21OudIinORN"
   },
   "source": [
    "# Inter-rater Agreement\n",
    "## Fleiss' Kappa\n",
    "\n",
    "Discretize the ratings in 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Joq3COs3nJIa"
   },
   "outputs": [],
   "source": [
    "n_cat, max_range = 5, 100 # number of categories\n",
    "data_discretized = []\n",
    "\n",
    "ids = [w['id'] for w in data]\n",
    "correctness = [int((n_cat* w['Correctness']) / (max_range+1)) for w in data]\n",
    "coverage = [int((n_cat* w['DataCoverage']) / (max_range+1)) for w in data]\n",
    "fluency = [int((n_cat* w['Fluency']) / (max_range+1)) for w in data]\n",
    "relevance = [int((n_cat* w['Relevance']) / (max_range+1)) for w in data]\n",
    "structure = [int((n_cat* w['TextStructure']) / (max_range+1)) for w in data]\n",
    "    \n",
    "for i, id_ in enumerate(ids):\n",
    "    for j, row in enumerate(data):\n",
    "        if row['id'] == id_:\n",
    "            row_ = copy.copy(row)\n",
    "            row_['Correctness'] = correctness[i]\n",
    "            row_['DataCoverage'] = coverage[i]\n",
    "            row_['Fluency'] = fluency[i]\n",
    "            row_['Relevance'] = relevance[i]\n",
    "            row_['TextStructure'] = structure[i]\n",
    "            data_discretized.append(row_)\n",
    "            break\n",
    "\n",
    "data_discretized = sorted(data_discretized, key=lambda x: x['id'])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3l96S0BnTgc"
   },
   "source": [
    "Computing the Fleiss' Kappa agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HJbiN24-nQaJ",
    "outputId": "8b5d466e-23ff-412b-8304-1f944fa4f618"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fleiss' Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correctness</th>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Coverage</th>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fluency</th>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevance</th>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text Structure</th>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fleiss' Kappa\n",
       "Correctness             0.244\n",
       "Data Coverage           0.435\n",
       "Fluency                 0.156\n",
       "Relevance               0.125\n",
       "Text Structure          0.132"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments = set([(w['submission_id'], w['sample_id']) for w in data_discretized])\n",
    "\n",
    "correctness = np.zeros((len(assignments), n_cat))\n",
    "coverage = np.zeros((len(assignments), n_cat))\n",
    "fluency = np.zeros((len(assignments), n_cat))\n",
    "relevance = np.zeros((len(assignments), n_cat))\n",
    "structure = np.zeros((len(assignments), n_cat))\n",
    "\n",
    "for i, (submission_id, sample_id) in enumerate(assignments):\n",
    "    fdata = [w for w in data_discretized if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
    "    \n",
    "    for rating in fdata:\n",
    "        correctness[i, rating['Correctness']-1] += 1\n",
    "        coverage[i, rating['DataCoverage']-1] += 1\n",
    "        fluency[i, rating['Fluency']-1] += 1\n",
    "        relevance[i, rating['Relevance']-1] += 1\n",
    "        structure[i, rating['TextStructure']-1] += 1      \n",
    "        \n",
    "pd.DataFrame({\"Fleiss' Kappa\": {\n",
    "    'Correctness': fleiss_kappa(correctness),\n",
    "    'Data Coverage': fleiss_kappa(coverage),\n",
    "    'Fluency': fleiss_kappa(fluency),\n",
    "    'Relevance': fleiss_kappa(relevance),\n",
    "    'Text Structure': fleiss_kappa(structure),\n",
    "}}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw8ORC8RnafX"
   },
   "source": [
    "# Human Evaluation\n",
    "\n",
    "Results of the human evaluation for the participating systems according to original ratings of correctness, data coverage, fluency, relevance and text structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "mN38HX8TnVU0",
    "outputId": "393e6f13-b5cb-42b2-9b83-26685681570a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d4032e5b288e>:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Correctness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DataCoverage</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fluency</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Relevance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TextStructure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>95.594</td>\n",
       "      <td>11.577</td>\n",
       "      <td>95.630</td>\n",
       "      <td>9.961</td>\n",
       "      <td>93.088</td>\n",
       "      <td>14.143</td>\n",
       "      <td>95.385</td>\n",
       "      <td>11.676</td>\n",
       "      <td>95.745</td>\n",
       "      <td>11.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>90.779</td>\n",
       "      <td>17.901</td>\n",
       "      <td>92.339</td>\n",
       "      <td>17.709</td>\n",
       "      <td>90.248</td>\n",
       "      <td>17.853</td>\n",
       "      <td>93.491</td>\n",
       "      <td>17.440</td>\n",
       "      <td>93.764</td>\n",
       "      <td>14.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>90.630</td>\n",
       "      <td>18.217</td>\n",
       "      <td>94.000</td>\n",
       "      <td>14.474</td>\n",
       "      <td>89.021</td>\n",
       "      <td>20.070</td>\n",
       "      <td>93.636</td>\n",
       "      <td>14.852</td>\n",
       "      <td>92.082</td>\n",
       "      <td>17.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>90.382</td>\n",
       "      <td>20.700</td>\n",
       "      <td>93.155</td>\n",
       "      <td>16.980</td>\n",
       "      <td>92.921</td>\n",
       "      <td>13.779</td>\n",
       "      <td>93.306</td>\n",
       "      <td>17.177</td>\n",
       "      <td>96.073</td>\n",
       "      <td>11.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>88.585</td>\n",
       "      <td>21.181</td>\n",
       "      <td>82.230</td>\n",
       "      <td>21.431</td>\n",
       "      <td>88.252</td>\n",
       "      <td>21.491</td>\n",
       "      <td>92.224</td>\n",
       "      <td>16.161</td>\n",
       "      <td>91.309</td>\n",
       "      <td>18.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>87.033</td>\n",
       "      <td>23.697</td>\n",
       "      <td>86.448</td>\n",
       "      <td>21.397</td>\n",
       "      <td>85.679</td>\n",
       "      <td>23.897</td>\n",
       "      <td>91.761</td>\n",
       "      <td>19.421</td>\n",
       "      <td>89.515</td>\n",
       "      <td>21.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>84.830</td>\n",
       "      <td>25.781</td>\n",
       "      <td>82.836</td>\n",
       "      <td>23.884</td>\n",
       "      <td>88.558</td>\n",
       "      <td>21.273</td>\n",
       "      <td>90.433</td>\n",
       "      <td>20.299</td>\n",
       "      <td>92.958</td>\n",
       "      <td>17.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>80.830</td>\n",
       "      <td>25.715</td>\n",
       "      <td>93.191</td>\n",
       "      <td>17.387</td>\n",
       "      <td>84.691</td>\n",
       "      <td>21.115</td>\n",
       "      <td>91.294</td>\n",
       "      <td>19.648</td>\n",
       "      <td>87.645</td>\n",
       "      <td>21.338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Correctness         DataCoverage         Fluency  \\\n",
       "                             mean     std         mean     std    mean   \n",
       "submission_id                                                            \n",
       "bt5                        95.594  11.577       95.630   9.961  93.088   \n",
       "FBConvAI                   90.779  17.901       92.339  17.709  90.248   \n",
       "WebNLG-2020-reference      90.630  18.217       94.000  14.474  89.021   \n",
       "cuni-ufal                  90.382  20.700       93.155  16.980  92.921   \n",
       "med                        88.585  21.181       82.230  21.431  88.252   \n",
       "Huawei_Noahs_Ark_Lab       87.033  23.697       86.448  21.397  85.679   \n",
       "OSU_Neural_NLG             84.830  25.781       82.836  23.884  88.558   \n",
       "Baseline-FORGE2020         80.830  25.715       93.191  17.387  84.691   \n",
       "\n",
       "                              Relevance         TextStructure          \n",
       "                          std      mean     std          mean     std  \n",
       "submission_id                                                          \n",
       "bt5                    14.143    95.385  11.676        95.745  11.601  \n",
       "FBConvAI               17.853    93.491  17.440        93.764  14.286  \n",
       "WebNLG-2020-reference  20.070    93.636  14.852        92.082  17.564  \n",
       "cuni-ufal              13.779    93.306  17.177        96.073  11.017  \n",
       "med                    21.491    92.224  16.161        91.309  18.479  \n",
       "Huawei_Noahs_Ark_Lab   23.897    91.761  19.421        89.515  21.019  \n",
       "OSU_Neural_NLG         21.273    90.433  20.299        92.958  17.266  \n",
       "Baseline-FORGE2020     21.115    91.294  19.648        87.645  21.338  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n",
    "submissions.agg([np.mean, np.std]).sort_values(by=('Correctness', 'mean'), ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o2sM3a1ne90"
   },
   "source": [
    "# Human Evaluation (Z-Scores)\n",
    "\n",
    "Results of the human evaluation for the participating systems according to normalized z-scores for correctness, data coverage, fluency, relevance and text structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "pPcXSN30nc7c",
    "outputId": "13f92cec-d00f-4a49-998b-7d8eaa49950e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-43e0951007bb>:27: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Correctness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DataCoverage</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fluency</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Relevance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TextStructure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submission_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>0.021</td>\n",
       "      <td>1.009</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>1.202</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>1.221</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1.001</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>-0.084</td>\n",
       "      <td>1.111</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.114</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>1.198</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>1.110</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>-0.181</td>\n",
       "      <td>1.179</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>1.325</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>1.104</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>-0.387</td>\n",
       "      <td>1.213</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>1.098</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>1.134</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>1.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Correctness        DataCoverage        Fluency         \\\n",
       "                             mean    std         mean    std    mean    std   \n",
       "submission_id                                                                 \n",
       "bt5                         0.340  0.586        0.312  0.534   0.232  0.613   \n",
       "WebNLG-2020-reference       0.109  0.794        0.230  0.707   0.022  0.960   \n",
       "cuni-ufal                   0.101  0.951        0.204  0.763   0.213  0.691   \n",
       "FBConvAI                    0.080  0.833        0.133  0.880   0.063  0.837   \n",
       "med                         0.021  1.009       -0.470  1.202  -0.060  1.221   \n",
       "Huawei_Noahs_Ark_Lab       -0.084  1.111       -0.189  1.114  -0.174  1.198   \n",
       "OSU_Neural_NLG             -0.181  1.179       -0.422  1.325  -0.050  1.104   \n",
       "Baseline-FORGE2020         -0.387  1.213        0.200  0.870  -0.247  1.098   \n",
       "\n",
       "                      Relevance        TextStructure         \n",
       "                           mean    std          mean    std  \n",
       "submission_id                                                \n",
       "bt5                       0.174  0.696         0.219  0.658  \n",
       "WebNLG-2020-reference     0.065  0.814        -0.005  0.969  \n",
       "cuni-ufal                 0.077  0.891         0.218  0.690  \n",
       "FBConvAI                  0.027  0.967         0.079  0.808  \n",
       "med                      -0.022  1.001        -0.077  1.195  \n",
       "Huawei_Noahs_Ark_Lab     -0.060  1.110        -0.183  1.211  \n",
       "OSU_Neural_NLG           -0.182  1.242         0.019  0.998  \n",
       "Baseline-FORGE2020       -0.079  1.134        -0.270  1.192  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normdata = []\n",
    "worker_ids = set([w['worker_id'] for w in data])\n",
    "for worker_id in worker_ids:\n",
    "    fdata = [w for w in data if w['worker_id'] == worker_id]\n",
    "    \n",
    "    ids = [w['id'] for w in fdata]\n",
    "    correctness = zscore([w['Correctness'] for w in fdata])\n",
    "    coverage = zscore([w['DataCoverage'] for w in fdata])\n",
    "    fluency = zscore([w['Fluency'] for w in fdata])\n",
    "    relevance = zscore([w['Relevance'] for w in fdata])\n",
    "    structure = zscore([w['TextStructure'] for w in fdata])\n",
    "    \n",
    "    for i, id_ in enumerate(ids):\n",
    "        for j, row in enumerate(data):\n",
    "            if row['id'] == id_:\n",
    "                row_ = copy.copy(row)\n",
    "                row_['Correctness'] = correctness[i]\n",
    "                row_['DataCoverage'] = coverage[i]\n",
    "                row_['Fluency'] = fluency[i]\n",
    "                row_['Relevance'] = relevance[i]\n",
    "                row_['TextStructure'] = structure[i]\n",
    "                normdata.append(row_)\n",
    "                break\n",
    "                \n",
    "df = pd.DataFrame(normdata)\n",
    "\n",
    "submissions = df.groupby(\"submission_id\")[\"Correctness\", \"DataCoverage\", \"Fluency\", \"Relevance\", \"TextStructure\"]\n",
    "submissions.agg([np.mean, np.std]).sort_values(by=('Correctness', 'mean'), ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pH-aSFE0nJUf"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "submission_ids = sorted(list(set([w['submission_id'] for w in normdata])))\n",
    "sample_ids = sorted(list(set([w['sample_id'] for w in normdata])), key=lambda x: int(x))\n",
    "\n",
    "finaldata = []\n",
    "for submission_id in submission_ids:\n",
    "  for sample_id in sample_ids:\n",
    "    fdata = [w for w in normdata if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
    "\n",
    "    if len(fdata) > 0:\n",
    "      finaldata.append({\n",
    "        'submission_id': submission_id,\n",
    "        'size': fdata[0]['size'],\n",
    "        'sample_id': sample_id,\n",
    "        'category': fdata[0]['category'],\n",
    "        'Correctness': np.nan_to_num(np.mean(np.nan_to_num([w['Correctness'] for w in fdata]))),\n",
    "        'DataCoverage': np.nan_to_num(np.mean(np.nan_to_num([w['DataCoverage'] for w in fdata]))),\n",
    "        'Fluency': np.nan_to_num(np.mean(np.nan_to_num([w['Fluency'] for w in fdata]))),\n",
    "        'Relevance': np.nan_to_num(np.mean(np.nan_to_num([w['Relevance'] for w in fdata]))),\n",
    "        'TextStructure': np.nan_to_num(np.mean(np.nan_to_num([w['TextStructure'] for w in fdata])))\n",
    "      })\n",
    "\n",
    "json.dump(finaldata, open('../../results/ru/russian_humeval_data_all_teams.json', 'w'), separators=(',', ':'), indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "160-jVRNnkHU"
   },
   "source": [
    "# Statistical Testing\n",
    "\n",
    "## Wilcoxon rank-sum significant test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tAdU6ffQnhFo"
   },
   "outputs": [],
   "source": [
    "def parse(data, normdata):\n",
    "    correctness, coverage, fluency, relevance, structure = {}, {}, {}, {}, {}\n",
    "    normcorrectness, normcoverage, normfluency, normrelevance, normstructure = {}, {}, {}, {}, {}\n",
    "\n",
    "    submission_ids = sorted(list(set([w['submission_id'] for w in data])))\n",
    "    sample_ids = sorted(list(set([w['sample_id'] for w in data])), key=lambda x: int(x))\n",
    "    for i, submission_id in enumerate(submission_ids):\n",
    "        if submission_id not in correctness:\n",
    "            correctness[submission_id] = []\n",
    "            coverage[submission_id] = []\n",
    "            fluency[submission_id] = []\n",
    "            relevance[submission_id] = []\n",
    "            structure[submission_id] = []\n",
    "\n",
    "            normcorrectness[submission_id] = []\n",
    "            normcoverage[submission_id] = []\n",
    "            normfluency[submission_id] = []\n",
    "            normrelevance[submission_id] = []\n",
    "            normstructure[submission_id] = []\n",
    "        \n",
    "        for sample_id in sample_ids:\n",
    "          fdata = [w for w in data if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
    "          fnormdata = [w for w in normdata if w['submission_id'] == submission_id and w['sample_id'] == sample_id]\n",
    "\n",
    "          correctness[submission_id].append(np.mean([w['Correctness'] for w in fdata]))\n",
    "          coverage[submission_id].append(np.mean([w['DataCoverage'] for w in fdata]))\n",
    "          fluency[submission_id].append(np.mean([w['Fluency'] for w in fdata]))\n",
    "          relevance[submission_id].append(np.mean([w['Relevance'] for w in fdata]))\n",
    "          structure[submission_id].append(np.mean([w['TextStructure'] for w in fdata]))\n",
    "\n",
    "          # Average the z-scores (setting nans to zeros) of the three turkers for each trial of each system\n",
    "          normcorrectness[submission_id].append(np.mean(np.nan_to_num([w['Correctness'] for w in fnormdata])))\n",
    "          normcoverage[submission_id].append(np.mean(np.nan_to_num([w['DataCoverage'] for w in fnormdata])))\n",
    "          normfluency[submission_id].append(np.mean(np.nan_to_num([w['Fluency'] for w in fnormdata])))\n",
    "          normrelevance[submission_id].append(np.mean(np.nan_to_num([w['Relevance'] for w in fnormdata])))\n",
    "          normstructure[submission_id].append(np.mean(np.nan_to_num([w['TextStructure'] for w in fnormdata])))\n",
    "    return correctness, coverage, fluency, relevance, structure, \\\n",
    "            normcorrectness, normcoverage, normfluency, normrelevance, normstructure\n",
    "    \n",
    "def rank_systems(X, raw_X, name):\n",
    "    submissions = sorted(X.keys(), key=lambda x: np.mean(X[x]), reverse=True)\n",
    "    ranking = { s:1 for i, s in enumerate(submissions) }\n",
    "\n",
    "    for i, subA in enumerate(submissions):\n",
    "        for j, subB in enumerate(submissions[i+1:]):\n",
    "            s, pvalue = ranksums(X[subA], X[subB])\n",
    "            if pvalue < 0.05:\n",
    "                ranking[subB] = ranking[subA] + 1\n",
    "            elif ranking[subB] < ranking[submissions[i+1+j-1]] :\n",
    "                ranking[subB] = ranking[submissions[i+1+j-1]] \n",
    "\n",
    "    ranking_ = {}\n",
    "    for sub in ranking:\n",
    "        rank = ranking[sub]\n",
    "        normmean = np.mean(X[sub])\n",
    "        mean = np.mean(raw_X[sub])\n",
    "        ranking_[sub] = { 'Ranking': int(rank), name + ' (Z.)': round(normmean, 3), name: round(mean, 3) }\n",
    "\n",
    "    return ranking_\n",
    "\n",
    "correctness, coverage, fluency, relevance, structure, \\\n",
    "      normcorrectness, normcoverage, normfluency, normrelevance, normstructure = parse(data, normdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_U7imwKnrzK"
   },
   "source": [
    "### All Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "NZ6_9w1Zno3l",
    "outputId": "87168808-097a-4c35-e0b9-584b43d7c415"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Correctness (Z.)</th>\n",
       "      <th>Correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>80.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>95.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.101</td>\n",
       "      <td>90.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>90.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>87.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>88.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>84.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>90.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ranking  Correctness (Z.)  Correctness\n",
       "Baseline-FORGE2020         4.0            -0.387       80.830\n",
       "bt5                        1.0             0.340       95.594\n",
       "cuni-ufal                  2.0             0.101       90.382\n",
       "FBConvAI                   2.0             0.080       90.779\n",
       "Huawei_Noahs_Ark_Lab       2.0            -0.084       87.033\n",
       "med                        2.0             0.021       88.585\n",
       "OSU_Neural_NLG             3.0            -0.181       84.830\n",
       "WebNLG-2020-reference      2.0             0.109       90.630"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rank_systems(normcorrectness, correctness, 'Correctness')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "5Dwu8595nqYC",
    "outputId": "ade2c328-5e38-4d7a-9558-66f7f2ff2110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Coverage (Z.)</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>93.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312</td>\n",
       "      <td>95.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>93.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>92.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>86.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>82.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>82.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ranking  Coverage (Z.)  Coverage\n",
       "Baseline-FORGE2020         1.0          0.200    93.191\n",
       "bt5                        1.0          0.312    95.630\n",
       "cuni-ufal                  1.0          0.203    93.155\n",
       "FBConvAI                   1.0          0.133    92.339\n",
       "Huawei_Noahs_Ark_Lab       2.0         -0.189    86.448\n",
       "med                        3.0         -0.467    82.230\n",
       "OSU_Neural_NLG             2.0         -0.422    82.836\n",
       "WebNLG-2020-reference      1.0          0.230    94.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rank_systems(normcoverage, coverage, 'Coverage')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "LWTa6Ub8nwhp",
    "outputId": "271e9b6e-8c5d-466e-a2a4-e9eb94a04195"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Fluency (Z.)</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>84.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>93.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213</td>\n",
       "      <td>92.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>90.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>85.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>88.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>88.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>89.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ranking  Fluency (Z.)  Fluency\n",
       "Baseline-FORGE2020         3.0        -0.247   84.691\n",
       "bt5                        1.0         0.232   93.088\n",
       "cuni-ufal                  1.0         0.213   92.921\n",
       "FBConvAI                   2.0         0.063   90.248\n",
       "Huawei_Noahs_Ark_Lab       3.0        -0.174   85.679\n",
       "med                        2.0        -0.060   88.252\n",
       "OSU_Neural_NLG             2.0        -0.050   88.558\n",
       "WebNLG-2020-reference      2.0         0.022   89.021"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rank_systems(normfluency, fluency, 'Fluency')).T.sort_index(axis=0, key=lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Qot2CPvanwlW",
    "outputId": "b8dff9eb-d4f3-4de4-a453-f566d535cb00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Relevance (Z.)</th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>91.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>95.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077</td>\n",
       "      <td>93.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>93.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>91.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>92.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>90.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>93.636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ranking  Relevance (Z.)  Relevance\n",
       "Baseline-FORGE2020         2.0          -0.079     91.294\n",
       "bt5                        1.0           0.174     95.385\n",
       "cuni-ufal                  1.0           0.077     93.306\n",
       "FBConvAI                   2.0           0.027     93.491\n",
       "Huawei_Noahs_Ark_Lab       2.0          -0.060     91.761\n",
       "med                        2.0          -0.022     92.224\n",
       "OSU_Neural_NLG             2.0          -0.182     90.433\n",
       "WebNLG-2020-reference      2.0           0.065     93.636"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rank_systems(normrelevance, relevance, 'Relevance')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "n56UvUUOnwn3",
    "outputId": "d7a1e173-d14e-42d0-8e75-3998150330b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Text Structure (Z.)</th>\n",
       "      <th>Text Structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline-FORGE2020</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>87.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>95.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuni-ufal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>96.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBConvAI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>93.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei_Noahs_Ark_Lab</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>89.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>91.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSU_Neural_NLG</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>92.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebNLG-2020-reference</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>92.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ranking  Text Structure (Z.)  Text Structure\n",
       "Baseline-FORGE2020         3.0               -0.270          87.645\n",
       "bt5                        1.0                0.219          95.745\n",
       "cuni-ufal                  1.0                0.218          96.073\n",
       "FBConvAI                   2.0                0.079          93.764\n",
       "Huawei_Noahs_Ark_Lab       3.0               -0.183          89.515\n",
       "med                        2.0               -0.077          91.309\n",
       "OSU_Neural_NLG             2.0                0.019          92.958\n",
       "WebNLG-2020-reference      2.0               -0.005          92.082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rank_systems(normstructure, structure, 'Text Structure')).T.sort_index(axis=0, key=lambda x: x.str.lower())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "webnlg_human_evaluation_russian.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
