<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="TIGERScore">
    <meta property="og:title" content="TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks" />
    <meta property="og:description" content="TIGERScore" />
    <meta property="og:url" content="https://tiger-ai-lab.github.io/TIGERScore/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TIGERScore">
    <meta name="twitter:description"
        content="TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Text Generation, Metrics">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>TIGERScore</title>

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
    <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
    <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            <img src="static/images/Logo.png" alt="TIGERScore Logo" height="60" />
                            TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <sup>â™¦</sup><a href="https://jdf-prog.github.io/" target="_blank">Dongfu
                                    Jiang</a><sup>*</sup>,</span>
                            <span class="author-block">
                                <sup>â™£</sup><a href="https://scholar.google.com/citations?user=5PfpWbAAAAAJ&hl=en"
                                    target="_blank">Yishan Li</a><sup>*</sup>,
                                <span class="author-block">
                                    <sup>â™¦</sup><a href="https://scholar.google.com/citations?user=qyTrq4kAAAAJ&hl=en"
                                        target="_blank">Ge Zhang</a>,
                                </span>
                                <span class="author-block">
                                    <sup>â™¡</sup><a
                                        href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=zh-CN"
                                        target="_blank">Wenhao Huang</a>,
                                </span>
                                <span class="author-block">
                                    <sup>â™ </sup><a href="https://yuchenlin.xyz/" target="_blank">Bill Yuchen Lin</a>,
                                </span>
                                <span class="author-block">
                                    <sup>â™¦</sup><a href="https://wenhuchen.github.io/" target="_blank">Wenhu Chen</a>
                                </span>
                        </div>



                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <sup>â™¦</sup>University of Waterloo,
                                <sup>â™£</sup>Tsinghua University,
                                <sup>â™¡</sup>IN.AI,
                                <sup>â™ </sup>Allen Institute for AI,
                                <span class="eql-cntrb"><small><br><sup>*</sup>Dongfu Jiang and Yishan Li have led the
                                        project and contributed equally to this project.</small></span><br />
                                <span class="author-block"><a
                                        href="mailto:dongfu.jiang@uwaterloo.ca">dongfu.jiang@uwaterloo.ca</a></span>,
                                <span class="author-block"><a
                                        href="mailto:liyisha19@mails.tsinghua.edu.cn">liyisha19@mails.tsinghua.edu.cn</a></span>
                                , <a href="mailto:wenhuchen@uwaterloo.ca">wenhuchen@uwaterloo.ca</a> </span>

                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://huggingface.co/datasets/TIGER-Lab/MetricInstruct" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            ðŸ¤—
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>

                                <!-- Supplementary PDF link -->
                                <span class="link-block">
                                    <a href="https://huggingface.co/TIGER-Lab/TIGERScore-13B-V1.2" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            ðŸ¤—
                                        </span>
                                        <span>Models</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a href="https://huggingface.co/spaces/TIGER-Lab/TIGERScore" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            ðŸ¤—
                                        </span>
                                        <span>Demo</span>
                                    </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                                    <a href="https://github.com/TIGER-AI-Lab/TIGERScore" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2310.00752" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <!-- Paper abstract -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                We present TIGERScore, a <b>T</b>rained metric that follows <b>I</b>nstruction
                                <b>G</b>uidance to perform <b>E</b>xplainable, and <b>R</b>eference-free evaluation over
                                a wide spectrum of text generation tasks.
                                Different from other automatic evaluation methods that only provide arcane scores,
                                TIGERScore is guided by the natural language instruction to provide error analysis to
                                pinpoint the mistakes in the generated text. Our metric is based on LLaMA,
                                trained on our meticulously curated instruction-tuning dataset MetricInstruct which
                                covers 6 text generation tasks and 22 text generation datasets. The dataset consists of
                                48K quadruple in the form of (instruction, input, system output, error analysis).
                                We collected the `system outputs' through diverse channels to cover different types of
                                errors. To quantitatively assess our metric, we evaluate its correlation with human
                                ratings on 5 held-in datasets,
                                2 held-out datasets and show that TIGERScore can achieve the highest overall Spearman's
                                correlation with human ratings across these datasets and outperforms other metrics
                                significantly. As a reference-free metric, its correlation can even surpass the best
                                existing reference-based metrics.
                                To further qualitatively assess the rationale generated by our metric, we conduct human
                                evaluation on the generated explanations and found that the explanations are 70.8%
                                accurate. Through these experimental results, we believe TIGERScore demonstrates the
                                possibility of building universal explainable metrics to evaluate any text generation
                                task.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->



    <!-- Image carousel -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/metric_overview2.png" alt="The perfermance of TIGERScore" />
                            <h2 class="subtitle;columns is-centered">
                                Figure 1: The upper part shows the input and output format of our metric. The lower part
                                shows te spearman's correlation of different metrics w.r.t human ratings.
                            </h2>
                        </div>
                    </div>
                </div>
                <div class="column is-fifths-fifths">
                    <p style="margin-left: 2em;margin-right: 2em;">
                        TIGERScore is built upon three design criteria: <br />
                    <p style="margin-left: 2em;margin-right: 2em;"><b>(1)</b> It is driven by instructions, making it
                        easily adaptable to any
                        text generation task. <br /></p>
                    <p style="margin-left: 2em;margin-right: 2em;"><b>(2)</b> The evaluation process eliminates the need
                        for a "gold standard"
                        or perfect example for comparison. <br /></p>
                    <p style="margin-left: 2em;margin-right: 2em;"><b>(3)</b> It is highly explainable, as the model can
                        generate an error
                        analysis that helps the user understand each identified mistake and its associated penalty.</p>
                    </p>
                </div>
            </div>
        </div>
    </section>
    <!-- End image carousel -->

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Our Dataset: MetricInstruct</h2>
                        <div class="column is-fifths-fifths">
                            <div class="item">
                                <!-- Your image here -->
                                <img src="static/images/pipeline.png" alt="The pipeline of MetricInstruct" />
                                <h2 class="subtitle;columns is-centered">
                                    Figure 2: Overall pipeline of constructing MetricInstruct through the two-channel
                                    collection.
                                </h2>
                            </div>
                        </div>
                        <div class="column is-fifths-fifths" style="margin-left: 2em;margin-right: 4em;">
                            <p>
                                We present the MetricInstruct dataset, which is employed to fine-tune TIGERScore. The
                                three
                                underlying criteria for dataset construction are: <br /><br /></p>
                            <p style="margin-left: 2em;margin-right: 2em;"><b>(1) Dataset diversity</b>: we choose 23
                                distinctive datasets as
                                the source context to cover enough generation tasks. <br /></p>
                            <p style="margin-left: 2em;margin-right: 2em;"><b>(2) Error coverage</b>: we take system
                                outputs generated from
                                50+ text generation systems to cover all types of errors and guarantee a balanced
                                distribution. <br /></p>
                            <p style="margin-left: 2em;margin-right: 2em;"><b>(3) Quality ensurance</b>: to ensure
                                MetricInstruct is tailored
                                to gather in-depth error analysis, we sourced it by prompting OpenAI GPT models and then
                                filtered through different heuristics to eliminate low-quality error analysis. <br />
                                <br />
                            </p>
                            <p>
                                Our system outputs come from two channels, namely real-world system outputs and
                                synthetic
                                outputs. The real-world system outputs are obtained from real systems, which ensures the
                                error distribution is aligned with real-world ones.
                            </p>
                        </div>
                        <!-- <br /><br />
                        <div class="content has-text-justified">
                            <table>
                                <thead>
                                    <tr>
                                        <td>Task</td>
                                        <td style="border-left: 1px solid #ddd;"> Real-World <br />Dataset</td>
                                        <td> <br />Output Source</td>
                                        <td> <br /># Sample</td>
                                        <td style="border-left: 1px solid #ddd;"> Synthetic <br />Dataset</td>
                                        <td> <br />Output Source</td>
                                        <td> <br /># Sample</td>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Summ</td>
                                        <td style="border-left: 1px solid #ddd;">SummEvalâ€¡, XSum,<br />Newsroom,SAMSum
                                        </td>
                                        <td>27 Systems</td>
                                        <td>4867</td>
                                        <td style="border-left: 1px solid #ddd;">CNN/DM, XSum,<br />Gigaword,SAMSum</td>
                                        <td>GPT-4</td>
                                        <td>400</td>
                                    </tr>
                                    <tr>
                                        <td>Trans</td>
                                        <td style="border-left: 1px solid #ddd;">WMTâ€¡</td>
                                        <td>18 Systems</td>
                                        <td>5708</td>
                                        <td style="border-left: 1px solid #ddd;">WMT</td>
                                        <td>GPT-4</td>
                                        <td>400</td>
                                    </tr>
                                    <tr>
                                        <td>D2T</td>
                                        <td style="border-left: 1px solid #ddd;">WebNLG-2020â€¡,<br />WikiTableText,ToTTo
                                        </td>
                                        <td>17 Systems</td>
                                        <td>56147</td>
                                        <td style="border-left: 1px solid #ddd;">WikiTableText,<br />Dart,ToTTo</td>
                                        <td>GPT-4</td>
                                        <td>400</td>
                                    </tr>
                                    <tr>
                                        <td>LF-QA</td>
                                        <td style="border-left: 1px solid #ddd;">ASQA,FeTaQA,<br />CosmosQA,ELI5</td>
                                        <td>5 Systems</td>
                                        <td>3352</td>
                                        <td style="border-left: 1px solid #ddd;">ASQA,FeTaQA<br />Cosmos QA,ELI5</td>
                                        <td>GPT-4</td>
                                        <td>1146</td>
                                    </tr>
                                    <tr>
                                        <td>MathQA</td>
                                        <td style="border-left: 1px solid #ddd;">GSM8K</td>
                                        <td>5 Systems</td>
                                        <td>3558</td>
                                        <td style="border-left: 1px solid #ddd;">GSM8K,MathQA</td>
                                        <td>GPT-4</td>
                                        <td>200</td>
                                    </tr>
                                    <tr>
                                        <td>Instruct</td>
                                        <td style="border-left: 1px solid #ddd;">MixInstructâ€¡</td>
                                        <td>11 Systems</td>
                                        <td>2248</td>
                                        <td style="border-left: 1px solid #ddd;">
                                            AlpacaFarm,OASST1<br />Guanaco,Dolly</td>
                                        <td>GPT-4</td>
                                        <td>3750</td>
                                    </tr>
                                </tbody>
                            </table>
                            <p>
                                Table 1: The composition of our training dataset. For synthetic data, the output is
                                generated by asking GPT-4
                                to synthesize incorrect outputs that contain a few specific types of errors. For the
                                datasets with â€¡,
                                we take their released system outputs. For the others, we collect the system outputs on
                                our own.
                            </p>
                        </div> -->
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Overall Results</h2>
                        <div class="content has-text-justified">
                            <p style="margin-left: 2em;margin-right: 2em;">
                                Nota bene that TIGERScore significantly surpasses traditional metrics, i.e. BLUE, ROUGE,
                                BARTScore, and BLEURT, and emerging LLM-based metrics as reference-free metrics.
                                Though our dataset was originally sourced from GPT-4, our distilled model actually
                                outperforms ChatGPT itself, which proves the effectiveness of our filtering strategy.
                                On the unseen task of story generation, TIGERScore also demonstrates reasonable
                                generalization capability.
                            </p>
                            <br /><br />
                            <table>
                                <tr>
                                    <td>Tasksâ†’</td>
                                    <td>Summarization</td>
                                    <td>Translation</td>
                                    <td>Data2Text</td>
                                    <td>Long-form QA</td>
                                    <td>MathQA</td>
                                    <td>Inst-Fol</td>
                                    <td>Story-Gen</td>
                                    <td>Average</td>
                                </tr>
                                <tr>
                                    <td>Metricsâ†“ Datasetsâ†’</td>
                                    <td>SummaEval</td>
                                    <td>WMT22-zh-en</td>
                                    <td>WebNLG2020</td>
                                    <td>ASQA+</td>
                                    <td>gsm8k</td>
                                    <td>LIMA+</td>
                                    <td>ROC</td>
                                    <td></td>
                                </tr>
                                <tr>
                                    <td>GPT-3.5-turbo (few-shot)</td>
                                    <td><b>38.50</b></td>
                                    <td>40.53</td>
                                    <td>40.20</td>
                                    <td>29.33</td>
                                    <td><b>66.46</b></td>
                                    <td>23.20</td>
                                    <td>4.77</td>
                                    <td>34.71</td>
                                </tr>
                                <tr>
                                    <td>GPT-4 (zero-shot)</td>
                                    <td>36.46</td>
                                    <td><b>43.87</b></td>
                                    <td><b>44.04</b></td>
                                    <td><b>48.95</b></td>
                                    <td>51.71</td>
                                    <td><b>58.53</b></td>
                                    <td><b>32.48</b></td>
                                    <td><b>45.15</b></td>
                                </tr>
                                <tr>
                                    <td>BLEU</td>
                                    <td>11.98</td>
                                    <td>19.73</td>
                                    <td>33.29</td>
                                    <td>11.38</td>
                                    <td>21.12</td>
                                    <td><b>46.61</b></td>
                                    <td>-1.17</td>
                                    <td>20.42</td>
                                </tr>
                                <tr>
                                    <td>ROUGE-2f</td>
                                    <td>14.53</td>
                                    <td>17.83</td>
                                    <td>35.49</td>
                                    <td>16.83</td>
                                    <td>22.12</td>
                                    <td>44.56</td>
                                    <td>2.34</td>
                                    <td>21.96</td>
                                </tr>
                                <tr>
                                    <td>InstructScore</td>
                                    <td>26.33</td>
                                    <td>47.30</td>
                                    <td>43.93</td>
                                    <td>21.62</td>
                                    <td>-4.15</td>
                                    <td>16.19</td>
                                    <td>16.13</td>
                                    <td>23.91</td>
                                </tr>
                                <tr>
                                    <td>GPTScore-ref</td>
                                    <td>14.73</td>
                                    <td>24.95</td>
                                    <td>39.42</td>
                                    <td>31.60</td>
                                    <td>18.20</td>
                                    <td>33.14</td>
                                    <td>18.24</td>
                                    <td>25.75</td>
                                </tr>
                                <tr>
                                    <td>BARTScore-cnn(hypo-ref)</td>
                                    <td>13.64</td>
                                    <td>28.53</td>
                                    <td>36.12</td>
                                    <td>29.57</td>
                                    <td><b>23.35</b></td>
                                    <td>32.49</td>
                                    <td>26.64</td>
                                    <td>27.19</td>
                                </tr>
                                <tr>
                                    <td>BARTScore-para (hypo-ref)</td>
                                    <td>17.18</td>
                                    <td>33.72</td>
                                    <td>40.79</td>
                                    <td>28.94</td>
                                    <td>17.27</td>
                                    <td>34.47</td>
                                    <td>17.43</td>
                                    <td>27.11</td>
                                </tr>
                                <tr>
                                    <td>BERTScore</td>
                                    <td>23.67</td>
                                    <td>42.41</td>
                                    <td>43.75</td>
                                    <td>25.60</td>
                                    <td>11.53</td>
                                    <td>45.77</td>
                                    <td>2.88</td>
                                    <td>27.95</td>
                                </tr>
                                <tr>
                                    <td>BLEURT</td>
                                    <td>17.30</td>
                                    <td>48.41</td>
                                    <td><b>48.76</b></td>
                                    <td>33.26</td>
                                    <td>3.53</td>
                                    <td>36.46</td>
                                    <td>27.52</td>
                                    <td>30.75</td>
                                </tr>
                                <tr>
                                    <td>UniEval(summ)</td>
                                    <td><b>47.52</b></td>
                                    <td>21.90</td>
                                    <td>38.38</td>
                                    <td><b>41.83</b></td>
                                    <td>19.78</td>
                                    <td>16.02</td>
                                    <td><b>44.46</b></td>
                                    <td>32.84</td>
                                </tr>
                                <tr>
                                    <td>COMET-22</td>
                                    <td>33.75</td>
                                    <td><b>56.35</b></td>
                                    <td>33.92</td>
                                    <td>35.28</td>
                                    <td>-5.53</td>
                                    <td>46.13</td>
                                    <td>39.20</td>
                                    <td><b>34.16</b></td>
                                </tr>
                                <tr>
                                    <td>BARTScore-para (src-hypo)</td>
                                    <td><b>38.68</b></td>
                                    <td>9.60</td>
                                    <td>32.26</td>
                                    <td>26.86</td>
                                    <td>-2.70</td>
                                    <td>5.92</td>
                                    <td>20.55</td>
                                    <td>18.74</td>
                                </tr>
                                <tr>
                                    <td>BARTScore-cnn (src-hypo)</td>
                                    <td>35.50</td>
                                    <td>12.83</td>
                                    <td>34.33</td>
                                    <td>40.96</td>
                                    <td>1.50</td>
                                    <td>25.43</td>
                                    <td>33.48</td>
                                    <td>26.29</td>
                                </tr>
                                <tr>
                                    <td>Llama-2-13b-chat-0-shot</td>
                                    <td>28.53</td>
                                    <td>14.38</td>
                                    <td>29.24</td>
                                    <td>19.91</td>
                                    <td>1.08</td>
                                    <td>21.37</td>
                                    <td>26.78</td>
                                    <td>20.18</td>
                                </tr>
                                <tr>
                                    <td>COMETKiwi</td>
                                    <td>16.27</td>
                                    <td><b>48.48</b></td>
                                    <td>27.90</td>
                                    <td>18.05</td>
                                    <td>-11.48</td>
                                    <td>34.86</td>
                                    <td>18.47</td>
                                    <td>21.79</td>
                                </tr>
                                <tr>
                                    <td>GPTScore-src</td>
                                    <td>37.41</td>
                                    <td>8.90</td>
                                    <td>28.82</td>
                                    <td>39.48</td>
                                    <td>14.25</td>
                                    <td>26.46</td>
                                    <td>23.91</td>
                                    <td>25.61</td>
                                </tr>
                                <tr>
                                    <td>TIGERScore-7B (ours)</td>
                                    <td>35.11</td>
                                    <td>41.50</td>
                                    <td>42.39</td>
                                    <td><b>47.11</b></td>
                                    <td>21.23</td>
                                    <td>43.57</td>
                                    <td>39.26</td>
                                    <td>38.60</td>
                                </tr>
                                <tr>
                                    <td>TIGERScore-13B (ours)</td>
                                    <td>36.81</td>
                                    <td>44.99</td>
                                    <td><b>45.88</b></td>
                                    <td>46.22</td>
                                    <td><b>23.32</b></td>
                                    <td><b>47.03</b></td>
                                    <td><b>46.36</b></td>
                                    <td><b>41.52</b></td>
                                </tr>
                                <tr>
                                    <td>Î” (ours - best reference-free)</td>
                                    <td>-2</td>
                                    <td>-3</td>
                                    <td>+12</td>
                                    <td>+5</td>
                                    <td>+9</td>
                                    <td>+14</td>
                                    <td>+13</td>
                                    <td>+16</td>
                                </tr>
                            </table>
                            <p>
                                Table 2:The Spearman correlation results of all the baseline metrics and TIGERScore on
                                the evaluation datasets shown in Table 3. For each task, the metric with the highest
                                correlation to average performance is highlighted in bold.
                            </p>
                            <br /><br />
                            <!-- <table>
                                <thead>
                                    <tr>
                                        <td>Task</td>
                                        <td>Eval Dataset</td>
                                        <td>Output Source</td>
                                        <td># Inputs</td>
                                        <td># Samples</td>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td colspan="5" style="text-align:center"> Held-in Evaluation Dataset (test set)
                                        </td>
                                    </tr>
                                    <tr>
                                        <td>Summarization</td>
                                        <td>SummEval</td>
                                        <td>16 Systems</td>
                                        <td>100</td>
                                        <td>1600</td>
                                    </tr>
                                    <tr>
                                        <td>Translation</td>
                                        <td>WMT-22 (zh-en)</td>
                                        <td>18 Systems</td>
                                        <td>1875</td>
                                        <td>33750</td>
                                    </tr>
                                    <tr>
                                        <td>Data to Text</td>
                                        <td>WebNLG-2020</td>
                                        <td>18 Systems</td>
                                        <td>179</td>
                                        <td>2848</td>
                                    </tr>
                                    <tr>
                                        <td>Long-form QA</td>
                                        <td>ASQA, FeTaQA, CosmosQA, ELI5</td>
                                        <td>4 Systems</td>
                                        <td>400</td>
                                        <td>1600</td>
                                    </tr>
                                    <tr>
                                        <td>Math QA</td>
                                        <td>GSM8K</td>
                                        <td>2 Systems</td>
                                        <td>1319</td>
                                        <td>2638</td>
                                    </tr>
                                    <tr>
                                        <td colspan="5" style="text-align:center"> Held-out Evaluation Dataset (test
                                            set)</td>
                                    </tr>
                                    <tr>
                                        <td>Instruct</td>
                                        <td>LIMA,AlpacaEval</td>
                                        <td>9 Systems</td>
                                        <td>500</td>
                                        <td>4500</td>
                                    </tr>
                                    <tr>
                                        <td>Story Generation</td>
                                        <td>OpenMEVA (ROC)</td>
                                        <td>5 Systems</td>
                                        <td>200</td>
                                        <td>1000</td>
                                    </tr>
                                </tbody>
                            </table>
                            <p>
                                Table 3:Overview of our main evaluation datasets. "# Samples" is computed by multipling
                                "# Inputs" with the number of outputs systems, representing the total instances that a
                                metric need to compute.
                            </p> -->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Human Evaluation</h2>
                        <div class="content has-text-justified">
                            <div style="margin-left: 2em;margin-right: 4em;">
                                <p>
                                    The reasonableness of the error analysis provided by TIGERScore was assessed through
                                    a
                                    random selection of 50 error analyses from each evaluation dataset. <br /><br />
                                    These error analyses are then evaluated by human experts who rated them from the
                                    following perspectives: <br />
                                <p style="margin-left: 2em;margin-right: 2em;"><b>Reasonableness:</b> The human experts
                                    directly pointed out
                                    which errors are problematic in error analyses, examining whether the analysis
                                    contained
                                    hallucination or illogical reasoning. <br /></p>
                                <p style="margin-left: 2em;margin-right: 2em;"><b>Comprehensiveness:</b> The human
                                    experts carefully review
                                    the source, output, and error analyses to determine if there are any additional
                                    errors
                                    unnoticed by TIGERScore.
                                    Based on human experts' analysis, they give a score on a scale of 1 to 4,
                                    specifically
                                    focused on identifying potential errors that may have been overlooked in the
                                    original
                                    analysis conducted by TIGERScore.<br /></p>
                                <p style="margin-left: 2em;margin-right: 2em;"><b>Effectiveness:</b> The revision
                                    suggestions in error
                                    analyses are evaluated by human experts, on a scale of 1 to 5, to determine their
                                    appropriateness and effectiveness in enhancing the output quantity.<br /></p>
                                <p style="margin-left: 2em;margin-right: 2em;"><b>Overall:</b> The Human experts further
                                    assign an overall
                                    score on a scale of 1 to 5 based on the reasonableness, comprehensiveness, and
                                    effectiveness of the error analysis.<br /></p>
                                </p>
                            </div>
                            <br /><br />
                            <th>
                                <table>
                                    <thead>
                                        <tr>
                                            <td>Aspects </td>
                                            <td colspan="2" style="text-align:center;border-left: 1px solid #ddd;">
                                                Explaination Error?</td>
                                            <td colspan="4" style="text-align:center;border-left: 1px solid #ddd;">
                                                Overlooked Errors</td>
                                            <td colspan="5" style="text-align:center;border-left: 1px solid #ddd;">
                                                Helpful
                                                of Revision Suggestions</td>
                                            <td colspan="5" style="text-align:center;border-left: 1px solid #ddd;">
                                                Overall
                                                Rating</td>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Taskâ†“ Rateâ†’</td>
                                            <td style="border-left: 1px solid #ddd;">Correct</td>
                                            <td>Wrong</td>
                                            <td style="border-left: 1px solid #ddd;">1</td>
                                            <td>2</td>
                                            <td>3</td>
                                            <td>4</td>
                                            <td style="border-left: 1px solid #ddd;">1</td>
                                            <td>2</td>
                                            <td>3</td>
                                            <td>4</td>
                                            <td>5</td>
                                            <td style="border-left: 1px solid #ddd;">1</td>
                                            <td>2</td>
                                            <td>3</td>
                                            <td>4</td>
                                            <td>5</td>
                                        </tr>
                                        <tr>
                                            <td>Sum</td>
                                            <td style="border-left: 1px solid #ddd;">70</td>
                                            <td><b>35</b></td>
                                            <td style="border-left: 1px solid #ddd;">2</td>
                                            <td><b>17</b></td>
                                            <td>15</td>
                                            <td>16</td>
                                            <td style="border-left: 1px solid #ddd;">6</td>
                                            <td>4</td>
                                            <td><b>19</b></td>
                                            <td>7</td>
                                            <td>14</td>
                                            <td style="border-left: 1px solid #ddd;">3</td>
                                            <td>10</td>
                                            <td><b>17</b></td>
                                            <td>7</td>
                                            <td>13</td>
                                        </tr>
                                        <tr>
                                            <td>Trans</td>
                                            <td style="border-left: 1px solid #ddd;"><b>54</b></td>
                                            <td>25</td>
                                            <td style="border-left: 1px solid #ddd;">3</td>
                                            <td>8</td>
                                            <td>17</td>
                                            <td><b>22</b></td>
                                            <td style="border-left: 1px solid #ddd;">2</td>
                                            <td>7</td>
                                            <td>17</td>
                                            <td>6</td>
                                            <td><b>18</b></td>
                                            <td style="border-left: 1px solid #ddd;">3</td>
                                            <td>6</td>
                                            <td>15</td>
                                            <td>9</td>
                                            <td><b>17</b></td>
                                        </tr>
                                        <tr>
                                            <td>D2T</td>
                                            <td style="border-left: 1px solid #ddd;">19</td>
                                            <td><b>21</b></td>
                                            <td style="border-left: 1px solid #ddd;">1</td>
                                            <td>8</td>
                                            <td>10</td>
                                            <td><b>31</b></td>
                                            <td style="border-left: 1px solid #ddd;">11</td>
                                            <td>8</td>
                                            <td>9</td>
                                            <td>3</td>
                                            <td><b>19</b></td>
                                            <td style="border-left: 1px solid #ddd;">11</td>
                                            <td>10</td>
                                            <td>4</td>
                                            <td>7</td>
                                            <td><b>18</b></td>
                                        </tr>
                                        <tr>
                                            <td>LF-QA</td>
                                            <td style="border-left: 1px solid #ddd;"><b>42</b></td>
                                            <td>19</td>
                                            <td style="border-left: 1px solid #ddd;">4</td>
                                            <td>10</td>
                                            <td>11</td>
                                            <td><b>25</b></td>
                                            <td style="border-left: 1px solid #ddd;">5</td>
                                            <td>8</td>
                                            <td>14</td>
                                            <td>7</td>
                                            <td><b>16</b></td>
                                            <td style="border-left: 1px solid #ddd;">6</td>
                                            <td>8</td>
                                            <td>10</td>
                                            <td>6</td>
                                            <td><b>20</b></td>
                                        </tr>
                                        <tr>
                                            <td>MathQA</td>
                                            <td style="border-left: 1px solid #ddd;"><b>39</b></td>
                                            <td>26</td>
                                            <td style="border-left: 1px solid #ddd;">5</td>
                                            <td>12</td>
                                            <td>12</td>
                                            <td><b>21</b></td>
                                            <td style="border-left: 1px solid #ddd;">5</td>
                                            <td>7</td>
                                            <td><b>19</b></td>
                                            <td>5</td>
                                            <td>14</td>
                                            <td style="border-left: 1px solid #ddd;">4</td>
                                            <td>9</td>
                                            <td>10</td>
                                            <td>13</td>
                                            <td><b>14</b></td>
                                        </tr>
                                        <tr>
                                            <td>Instruct</td>
                                            <td style="border-left: 1px solid #ddd;">5</td>
                                            <td><b>9</b></td>
                                            <td style="border-left: 1px solid #ddd;">5</td>
                                            <td>5</td>
                                            <td>8</td>
                                            <td><b>32</b></td>
                                            <td style="border-left: 1px solid #ddd;"><b>21</b></td>
                                            <td>3</td>
                                            <td>5</td>
                                            <td>2</td>
                                            <td>19</td>
                                            <td style="border-left: 1px solid #ddd;">9</td>
                                            <td>4</td>
                                            <td>3</td>
                                            <td>7</td>
                                            <td><b>27</b></td>
                                        </tr>
                                        <tr>
                                            <td>StoryGen</td>
                                            <td style="border-left: 1px solid #ddd;"><b>66</b></td>
                                            <td>29</td>
                                            <td style="border-left: 1px solid #ddd;">7</td>
                                            <td><b>16</b></td>
                                            <td>13</td>
                                            <td>14</td>
                                            <td style="border-left: 1px solid #ddd;">7</td>
                                            <td>6</td>
                                            <td><b>16</b></td>
                                            <td>10</td>
                                            <td>11</td>
                                            <td style="border-left: 1px solid #ddd;">7</td>
                                            <td><b>12</b></td>
                                            <td>11</td>
                                            <td>9</td>
                                            <td>11</td>
                                        </tr>
                                        <tr>
                                            <td>Total</td>
                                            <td style="border-left: 1px solid #ddd;"><b>295</b></td>
                                            <td>164</td>
                                            <td style="border-left: 1px solid #ddd;">27</td>
                                            <td>76</td>
                                            <td>86</td>
                                            <td><b>161</b></td>
                                            <td style="border-left: 1px solid #ddd;">57</td>
                                            <td>43</td>
                                            <td>99</td>
                                            <td>40</td>
                                            <td><b>111</b></td>
                                            <td style="border-left: 1px solid #ddd;">43</td>
                                            <td>59</td>
                                            <td>70</td>
                                            <td>58</td>
                                            <td><b>120</b></td>
                                        </tr>
                                    </tbody>
                                </table>
                            </th>
                            <p>
                                Table 4:Human evaluation results, the first question is asked per error in error
                                analyses, and the others are per sample. Superior performance is indicated by higher
                                numerical values. The most-voted rate of each task for each human evaluation aspect is
                                bolded.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">

                <div class="columns is-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Two Channel Data Collection</h2>
                        <div class="column is-fifths-fifths">

                            <div class="item">
                                <!-- Your image here -->
                                <img src="static/images/channel_test.png"
                                    alt="The different perfermance among different data source" />
                                <h2 class="subtitle;columns is-centered">
                                    Figure 3: Investigation of the influence of Real-World & Synthesic mix training on
                                    the 13B model.
                            </div>
                        </div>
                        <div style="margin-left: 2em;margin-right: 4em;">
                            <p>
                                To investigate the significance of our two-channel data in contributing to the strong
                                performance of TIGERScore, we conducted a series of experiments with the following
                                setups:<br /><br />
                            <p style="margin-left: 2em;margin-right: 2em;"><b>TIGERScore
                                    (MetricInstruct-Real-World)</b>, which aimed to
                                assess the quality of our real-world data and evaluate how to represent real-world data.
                                <br />
                            </p>
                            <p style="margin-left: 2em;margin-right: 2em;"><b>TIGERScore (MetricInstruct-Synthesic)</b>,
                                which aimed to
                                evaluate the impact of our synthetic data in enhancing quality as the complement.<br />
                            </p>
                            <p style="margin-left: 2em;margin-right: 2em;"><b>TIGERScore (MetricInstruct-Mix)</b>, our
                                official model, to
                                assess the combined effect of using both types of data during training.<br /></p>
                            <br />
                            <p>
                                The results demonstrate that TIGERScore(MetricInstruct-Mix) outperforms other methods
                                for
                                most tasks, followed by TIGERScore(MetricInstruct-Real-World), indicating that the
                                real-world channel data in MetricInstruct is effectively represented. Despite the subpar
                                performance of TIGERScore (MetricInstruct-Synthetic), the significant improvement
                                between
                                TIGERScore(MetricInstruct-Mix) and TIGERScore(MetricInstruct-Real-World) suggests that
                                synthetic data in MetricInstruct serves as a valuable supplement, enhancing the
                                robustness
                                of our model.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">Reference</h2>
            Please kindly cite our paper if you use our code, data, models or results:
            <br><br>
            <pre><code>@article{jiang2023TIGERScore,
  title={TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks},
  author={Dongfu Jiang, Yishan Li, Ge Zhang, Wenhao Huang, Bill Yuchen Lin, Wenhu Chen},
  journal={arXiv preprint arXiv:2310.00752},
  year={2023}
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. You are free
                            to borrow the of this website, we just ask that you link back to this page in the footer.
                            <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>



</html>