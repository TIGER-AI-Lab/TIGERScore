
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="TIGERScore">
    <meta property="og:title" content="TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks" />
    <meta property="og:description" content="TIGERScore" />
    <meta property="og:url" content="https://tiger-ai-lab.github.io/TIGERScore/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TIGERScore">
    <meta name="twitter:description" content="TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Text Generation, Metrics">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>TigerScore</title>

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
    <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
    <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title"> TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                <sup>â™¦</sup><a href="https://jdf-prog.github.io/" target="_blank">Dongfu Jiang</a><sup>*</sup>,</span>
                            <span class="author-block">
                  <sup>â™£</sup><a href="https://scholar.google.com/citations?user=5PfpWbAAAAAJ&hl=en" target="_blank">Yishan Li</a><sup>*</sup>,
                            <span class="author-block">
                    <sup>â™¦</sup><a href="https://scholar.google.com/citations?user=qyTrq4kAAAAJ&hl=en" target="_blank">Ge Zhang</a>,
                  </span>
                            <span class="author-block">
                    <sup>â™¡</sup><a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=zh-CN" target="_blank">Wenhao Huang</a>,
                  </span>
                            <span class="author-block">
                    <sup>â™ </sup><a href="https://yuchenlin.xyz/" target="_blank">Bill Yuchen Lin</a>,
                  </span>
                            <span class="author-block">
                    <sup>â™¦</sup><a href="https://wenhuchen.github.io/" target="_blank">Wenhu Chen</a>
                  </span>
                        </div>



                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                    <sup>â™¦</sup>University of Waterloo,
                    <sup>â™£</sup>Tsinghua University, 
                    <sup>â™¡</sup>IN.AI,
                    <sup>â™ </sup>Allen Institute for AI,                     
                    <span class="eql-cntrb"><small><br><sup>*</sup>Dongfu Jiang and Yishan Li have led the project and contributed equally to this project.</small></span><br/>
                            <span class="author-block"><a href="mailto:dongfu.jiang@uwaterloo.ca">dongfu.jiang@uwaterloo.ca</a></span>,
                            <span class="author-block"><a href="mailto:liyisha19@mails.tsinghua.edu.cn">liyisha19@mails.tsinghua.edu.cn</a></span>
                      , <a href="mailto:wenhuchen@uwaterloo.ca">wenhuchen@uwaterloo.ca</a> </span>

                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                          <a href="https://huggingface.co/datasets/TIGER-Lab/MetricInstruct" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            ðŸ¤—
                          </span>
                                <span>Dataset</span>
                                </a>
                                </span>

                                <!-- Supplementary PDF link -->
                                <span class="link-block">
                        <a href="https://huggingface.co/TIGER-Lab/TIGERScore-13B-V1.0" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          ðŸ¤—
                        </span>
                                <span>Models</span>
                                </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                      <a href="https://github.com/TIGER-AI-Lab/TIGERScore" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                                <span>Code</span>
                                </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                    <a href="https://arxiv.org/abs/2310.00752" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                                <span>arXiv</span>
                                </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <!-- Paper abstract -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                We present TIGERScore, a <b>T</b>rained metric that follows <b>I</b>nstruction <b>G</b>uidance to perform <b>E</b>, and <b>R</b>eference-free evaluation over a wide spectrum of text generation tasks. 
                                Different from other automatic evaluation methods that only provide arcane scores, TIGERScore is guided by the natural language instruction to provide error analysis to pinpoint the mistakes in the generated text. Our metric is based on LLaMA, 
                                trained on our meticulously curated instruction-tuning dataset MetricInstruct which covers 6 text generation tasks and 23 text generation datasets. The dataset consists of 48K quadruple in the form of (instruction, input, system output, error analysis). 
                                We collected the `system outputs' through diverse channels to cover different types of errors. To quantitatively assess our metric, we evaluate its correlation with human ratings on 5 held-in datasets, 
                                2 held-out datasets and show that TIGERScore can achieve the highest overall Spearman's correlation with human ratings across these datasets and outperforms other metrics significantly. As a reference-free metric, its correlation can even surpass the best existing reference-based metrics. 
                                To further qualitatively assess the rationale generated by our metric, we conduct human evaluation on the generated explanations and found that the explanations are 70.8% accurate. Through these experimental results, we believe TIGERScore demonstrates the possibility of building universal explainable metrics to evaluate any text generation task.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->



    <!-- Image carousel -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/metric_overview2.png" alt="The perfermance of TIGERScore" />
                            <h2 class="subtitle">
                                Figure 1: The upper part shows the input and output format of our metric. The lower part shows te spearman's correlation of different metrics w.r.t human ratings.
                            </h2>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End image carousel -->

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Our Dataset: MetricInstruct</h2>
                        <div class="content has-text-justified">
                            <table id="myTable"> 
                                <thead>
                                    <tr>
                                        <td>Task</td>
                                        <td>Real-World (training set)<br/>Dataset</td>
                                        <td>Synthetic (training set)<br/>Output Source</td>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Summ</td>
                                        <td>SummEvalâ€¡, XSum,<br/>Newsroom,SAMSum</td>
                                        <td>27 Systems</td>
                                    </tr>
                                    <tr>
                                        <td>Trans</td>
                                        <td>WMTâ€¡</td>
                                        <td>18 Systems</td>
                                    </tr>
                                    <tr>
                                        <td>D2T</td>
                                        <td>WebNLG-2020â€¡,<br/>WikiTableText,ToTTo</td>
                                        <td>17 Systems</td>
                                    </tr>
                                    <tr>
                                        <td>LF-QA</td>
                                        <td>ASQA,FeTaQA,<br/>CosmosQA,ELI5</td>
                                        <td>5 Systems</td>
                                    </tr>
                                    <tr>
                                        <td>MathQA</td>
                                        <td>GSM8K</td>
                                        <td>5 Systems</td>
                                    </tr>
                                    <tr>
                                        <td>Instruct</td>
                                        <td>MixInstructâ€¡</td>
                                        <td>11 Systems</td>
                                    </tr>
                                </tbody>
                            </table>
                            <p>
                                The composition of our dataset. For synthetic data, the output is generated by asking GPT-4
                                to synthesize incorrect outputs that contain a few specific types of errors. For the datasets with â€¡,
                                we take their released system outputs. For the others, we collect the system outputs on our own.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Pipeline to construct MetricInstruct</h2>
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/pipeline.png" alt="MY ALT TEXT" />
                            <h2 class="subtitle has-text-centered">
                                Figure 2: Overall pipeline to construct MetricInstruct
                            </h2>
                            <p>
                                [todo: explain the two channel briefly]
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">TIGERScore correlation analysis with human ratings</h2>
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/main_corr.png" alt="MY ALT TEXT" />
                            <h2 class="subtitle has-text-centered">
                                Table 1: The Spearman correlation results of all the baseline metrics and TIGERSCORE on the evaluation datasets. For each task, the metric with the highest correlation to
                                average performance is highlighted in bold.
                            </h2>
                            <p>
                                [todo: explain the the results briefly]
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Where does the gain come from?</h2>
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/ablation_channel.svg" alt="MY ALT TEXT" />
                            <h2 class="subtitle">
                                Figure 3: Investigation of the influence of Real-World & Synthesic mix training on the 13B model.
                            </h2>
                            <p>
                                In order to better understand what factors contribute to the great gain of ðŸ¦£MAmmoTH over existing baselines, we set up a group of control experiments in the Figure 3. We study the following setups:
                                <ol>
                                    <li>ðŸ¦£<b>MAmmoTH (MathInstruct - CoT):</b> This experiment aims to understand how much our curated CoT data could improve the generalization over the SoTA model WizardMath trained specifically on GSM + MATH. As can be seen,
                                        while sacrificing accuracy on GSM + MATH by 3%, our CoT subset fine-tuning improves the overall nine-dataset accuracy from 27% to 32%. </li>
                                    <li>ðŸ¦£<b>MAmmoTH (MathInstruct - PoT):</b> This experiment aims to understand the advantage of our PoT subset. As can be observed, our PoT subset fine-tuning can significantly improve the overall accuracy from 27% to 37.5%.
                                        This ablation reflects the importance of unlocking the program generation capabilities of our model.</li>
                                    <li>ðŸ¦£<b>MAmmoTH (MathInstruct - Hybrid):</b> We further combine CoT and PoT as the hybrid training data to achieve the best overall performance of 45.4%. This combined gain comes from two aspects:
                                        <ul style="list-style-type: disc;">
                                            <li>
                                                The CoT subset can help maintain the generic language-based reasoning skills to handle scenarios where PoT cannot handle well, e.g., the multi-choice questions in AQuA, SAT, and MMLU.
                                            </li>
                                            <li>
                                                The PoT subset can teach the model how to utilize Python APIs to solve complex math problems with high precision, e.g., the MATH problems requiring complex computation.
                                            </li>
                                        </ul>
                                    </li>
                                </ol>





                                <!-- We put some case studies in Appendix \ref{sec:case_study} to demonstrate the respective advantages of PoT and CoT in solving different types of math problems. To summarize, we attribute our substantial gain to: 1) diverse data sources covering different math fields and complexity levels and 2) a hybrid of CoT \& PoT instruction tuning strategy.  -->

                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <section class="hero is-small">
        <div class="hero-body">
            <div class="container  is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Human evaluation of explanation quality</h2>
                        <div class="item">
                            <!-- Your image here -->
                            <img src="static/images/human_eval.png" alt="MY ALT TEXT" />
                            <h2 class="subtitle has-text-centered">
                                Table 2: Human evaluation results, the first question is asked per error in error analyses, and the others are per sample. Superior performance is indicated by higher numerical values. The most-voted rate of each task for each human evaluation aspect is bolded.
                            </h2>
                            <p>
                                [todo: explain the the results briefly]
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>




    <!-- <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered is-fifths-fifths">
                        <h2 class="title is-3">Comprehensive Results: Break Down</h2>
                        <div class="content has-text-justified">
                            <div class="buttonGroup">
                                <button value="ALL">All</button>
                                <button value="CS">Closed-source</button>
                                <button value="7B">7B Parameter</button>
                                <button value="13_15B">13-15B Parameter</button>
                                <button value="30_34B">30-34B Parameter</button>
                                <button value="65_70B">65-70B Parameter</button>
                            </div>
                            <table>
                                <thead>
                                    <tr>
                                        <th>Model</th>
                                        <th>GSM8K</th>
                                        <th>MATH</th>
                                        <th>AQuA</th>
                                        <th>NumG</th>
                                        <th>SVAMP</th>
                                        <th>Mathematics</th>
                                        <th>SimulEq</th>
                                        <th>SAT</th>
                                        <th>MMLU</th>
                                    </tr>
                                    <tr>
                                    </tr>
                                </thead>
                                <tbody id="tabResults">
                                    <tr class="th">
                                        <td id="CS" colspan="14" style="text-align: center; font-weight: bold;">Closed-source Model</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>GPT-4</td>
                                        <td>-</td>
                                        <td>Unknown</td>
                                        <td>92</td>
                                        <td>42.5</td>
                                        <td>72.6</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>97</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>95</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Code-Interpreter</td>
                                        <td>-</td>
                                        <td>Unknown</td>
                                        <td>97</td>
                                        <td>69.7</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>PaLM-2</td>
                                        <td>-</td>
                                        <td>Unknown</td>
                                        <td>80.7</td>
                                        <td>34.3</td>
                                        <td>64.1</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>Claude-2</td>
                                        <td>-</td>
                                        <td>Unknown</td>
                                        <td>85.2</td>
                                        <td>32.5</td>
                                        <td>60.9</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>Codex (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>71.6</td>
                                        <td>36.8</td>
                                        <td>54.1</td>
                                        <td>-</td>
                                        <td>- </td>
                                        <td>85.2</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>68</td>
                                        <td>-</td>
                                        <td>- </td>
                                    </tr>
                                    <tr>
                                    </tr>

                                    <tr class="th">
                                        <td id="7B" colspan="14" style="text-align: center; font-weight: bold;">7B Parameter Model</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>10.7</td>
                                        <td>2.9</td>
                                        <td>22.6</td>
                                        <td>24.7</td>
                                        <td>15.5</td>
                                        <td>24.5</td>
                                        <td>6.2</td>
                                        <td>4.6</td>
                                        <td>22.7</td>
                                        <td>30.6</td>
                                        <td>17.7</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-2</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>14.6</td>
                                        <td>2.5</td>
                                        <td>30.3</td>
                                        <td>29.9</td>
                                        <td>19.3</td>
                                        <td>34.5</td>
                                        <td>6</td>
                                        <td>5</td>
                                        <td>26.8</td>
                                        <td>29.8</td>
                                        <td>20.4</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Galactica-6.7B</td>
                                        <td>GAL</td>
                                        <td>GAL-Instruct</td>
                                        <td>10.2</td>
                                        <td>2.2</td>
                                        <td>25.6</td>
                                        <td>25.8</td>
                                        <td>15.9</td>
                                        <td>25.6</td>
                                        <td>4.6</td>
                                        <td>4.2</td>
                                        <td>17.5</td>
                                        <td>28</td>
                                        <td>16</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Code-Llama (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>25.2</td>
                                        <td>14.2</td>
                                        <td>24</td>
                                        <td>26.8</td>
                                        <td>22.3 </td>
                                        <td>49.4</td>
                                        <td>21.7</td>
                                        <td>3.5</td>
                                        <td>28.6</td>
                                        <td>26.9</td>
                                        <td>26 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>AQuA-SFT</td>
                                        <td>Llama-2</td>
                                        <td>AQuA</td>
                                        <td>11.2</td>
                                        <td>3.6</td>
                                        <td>35.6</td>
                                        <td>12.2</td>
                                        <td>15.6 </td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>Llama-1 RFT</td>
                                        <td>Llama-1</td>
                                        <td>GSM8K</td>
                                        <td>46.5</td>
                                        <td>5.2</td>
                                        <td>18.8</td>
                                        <td>21.1</td>
                                        <td>22.9 </td>
                                        <td>21.1</td>
                                        <td>5.1</td>
                                        <td>11</td>
                                        <td>12.5</td>
                                        <td>21.7</td>
                                        <td>14.3 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>WizardMath</td>
                                        <td>Llama-2</td>
                                        <td>GSM8K+MATH</td>
                                        <td>54.9</td>
                                        <td>10.7</td>
                                        <td>26.3</td>
                                        <td>36.1</td>
                                        <td>32 </td>
                                        <td>36.1</td>
                                        <td>9.3</td>
                                        <td>12.8</td>
                                        <td>25.4</td>
                                        <td>31.1</td>
                                        <td>28.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTH</td>
                                        <td>Llama-2</td>
                                        <td>MathInstruct</td>
                                        <td>51.7</td>
                                        <td>31.2</td>
                                        <td>42.9</td>
                                        <td>53.1</td>
                                        <td>44.7 </td>
                                        <td>66.7</td>
                                        <td>44.8</td>
                                        <td>42</td>
                                        <td>36.4</td>
                                        <td>38.6</td>
                                        <td>45.7 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTHc</td>
                                        <td>Code-Llama</td>
                                        <td>MathInstruct</td>
                                        <td>58.8</td>
                                        <td>35.2</td>
                                        <td>43</td>
                                        <td>57.1</td>
                                        <td>48.5 </td>
                                        <td>71.1</td>
                                        <td>53.9</td>
                                        <td>44.6</td>
                                        <td>40</td>
                                        <td>40.5</td>
                                        <td>50.2 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>$\Delta$</td>
                                        <td></td>
                                        <td></td>
                                        <td>+4</td>
                                        <td>+21</td>
                                        <td>+8</td>
                                        <td>+21</td>
                                        <td>+16 </td>
                                        <td>+22</td>
                                        <td>+32</td>
                                        <td>+32</td>
                                        <td>+12</td>
                                        <td>+9</td>
                                        <td>+22 </td>
                                    </tr>
                                    <tr>
                                    </tr>

                                    <tr class="th">
                                        <td id="13_15B" colspan="14" style="text-align: center; font-weight: bold;">13-15B Parameter Model</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>17.8</td>
                                        <td>3.9</td>
                                        <td>26</td>
                                        <td>24.8</td>
                                        <td>18.1 </td>
                                        <td>34.7</td>
                                        <td>6.9</td>
                                        <td>5.4</td>
                                        <td>27.7</td>
                                        <td>30.7</td>
                                        <td>21 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-2</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>28.7</td>
                                        <td>3.9</td>
                                        <td>25.1</td>
                                        <td>8.8</td>
                                        <td>16.6 </td>
                                        <td>35.1</td>
                                        <td>11.5</td>
                                        <td>5.8</td>
                                        <td>32.7</td>
                                        <td>34.4</td>
                                        <td>23.9 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Code-Llama (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>36.1</td>
                                        <td>18.1</td>
                                        <td>28.7</td>
                                        <td>29.2</td>
                                        <td>28 </td>
                                        <td>60</td>
                                        <td>21.3</td>
                                        <td>3.8</td>
                                        <td>25.9</td>
                                        <td>27.7</td>
                                        <td>27.7 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>CodeT5+ (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>12.5</td>
                                        <td>2.4</td>
                                        <td>20.5</td>
                                        <td>19.4</td>
                                        <td>13.7 </td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>CodeGen+ (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>12.7</td>
                                        <td>3.4</td>
                                        <td>24.5</td>
                                        <td>22.5</td>
                                        <td>15.7 </td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                        <td>-</td>
                                    </tr>
                                    <tr>
                                        <td>Vicuna-1.5</td>
                                        <td>Llama-2</td>
                                        <td>No</td>
                                        <td>28.4</td>
                                        <td>5.8</td>
                                        <td>24.8</td>
                                        <td>36.9</td>
                                        <td>23.9 </td>
                                        <td>55.7</td>
                                        <td>10</td>
                                        <td>6.6</td>
                                        <td>34</td>
                                        <td>34.1</td>
                                        <td>28.1 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1 RFT</td>
                                        <td>Llama-1</td>
                                        <td>GSM8K</td>
                                        <td>52.1</td>
                                        <td>5.1</td>
                                        <td>16.1</td>
                                        <td>24.5</td>
                                        <td>24.4 </td>
                                        <td>46.5</td>
                                        <td>6.7</td>
                                        <td>10.1</td>
                                        <td>13.2</td>
                                        <td>21.6</td>
                                        <td>19.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Orca-Platypus</td>
                                        <td>Llama-2</td>
                                        <td>Platypus</td>
                                        <td>38.4</td>
                                        <td>3</td>
                                        <td>18.9</td>
                                        <td>35.3</td>
                                        <td>23.9 </td>
                                        <td>56.8</td>
                                        <td>12.6</td>
                                        <td>7.9</td>
                                        <td>29.5</td>
                                        <td>41.6</td>
                                        <td>29.7 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Platypus</td>
                                        <td>Llama-2</td>
                                        <td>Platypus</td>
                                        <td>25.7</td>
                                        <td>2.5</td>
                                        <td>33.4</td>
                                        <td>42.3</td>
                                        <td>25.9 </td>
                                        <td>55.4</td>
                                        <td>11.4</td>
                                        <td>7.4</td>
                                        <td>36.8</td>
                                        <td>35.5</td>
                                        <td>29.3 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>WizardMath</td>
                                        <td>Llama-2</td>
                                        <td>GSM8K+MATH</td>
                                        <td>63.9</td>
                                        <td>14</td>
                                        <td>21.2</td>
                                        <td>40.8</td>
                                        <td>34.9 </td>
                                        <td>51.9</td>
                                        <td>14.1</td>
                                        <td>14.9</td>
                                        <td>24.5</td>
                                        <td>32.1</td>
                                        <td>27.5 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTH</td>
                                        <td>Llama-2</td>
                                        <td>MathInstruct</td>
                                        <td>61.7</td>
                                        <td>36</td>
                                        <td>44.8</td>
                                        <td>59.6</td>
                                        <td>50.5 </td>
                                        <td>72.4</td>
                                        <td>48.7</td>
                                        <td>40.5</td>
                                        <td>42.7</td>
                                        <td>45.3</td>
                                        <td>49.9 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTHc</td>
                                        <td>Code-Llama</td>
                                        <td>MathInstruct</td>
                                        <td>64.3</td>
                                        <td>38.6</td>
                                        <td>46.1</td>
                                        <td>54.2</td>
                                        <td>50.8 </td>
                                        <td>73.2</td>
                                        <td>60</td>
                                        <td>44.1</td>
                                        <td>40.9</td>
                                        <td>45.2</td>
                                        <td>52.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>$\Delta$</td>
                                        <td></td>
                                        <td></td>
                                        <td>0</td>
                                        <td>+20</td>
                                        <td>+13</td>
                                        <td>+17</td>
                                        <td>+16 </td>
                                        <td>+13</td>
                                        <td>+39</td>
                                        <td>+30</td>
                                        <td>+6</td>
                                        <td>+4</td>
                                        <td>+23 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr class="th">
                                        <td id="30_34B" colspan="14" style="text-align: center; font-weight: bold;">30-34B Parameter Model</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>35.6</td>
                                        <td>7.1</td>
                                        <td>33.4</td>
                                        <td>28.4</td>
                                        <td>26.1 </td>
                                        <td>48.8</td>
                                        <td>12.8</td>
                                        <td>11.2</td>
                                        <td>33.4</td>
                                        <td>39</td>
                                        <td>29 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Code-Llama (PoT)</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>44</td>
                                        <td>25</td>
                                        <td>25.2</td>
                                        <td>29.3</td>
                                        <td>30.8 </td>
                                        <td>69.1</td>
                                        <td>34.5</td>
                                        <td>6.8</td>
                                        <td>26.8</td>
                                        <td>21.6</td>
                                        <td>31.7 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1 RFT</td>
                                        <td>Llama-1</td>
                                        <td>GSM8K</td>
                                        <td>56.5</td>
                                        <td>7.4</td>
                                        <td>18.5</td>
                                        <td>24.3</td>
                                        <td>26.6 </td>
                                        <td>55.4</td>
                                        <td>7.6</td>
                                        <td>12.8</td>
                                        <td>20.4</td>
                                        <td>37.9</td>
                                        <td>26.8 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Galactica-30B</td>
                                        <td>GAL</td>
                                        <td>GAL-Instruct</td>
                                        <td>41.7</td>
                                        <td>12.7</td>
                                        <td>28.7</td>
                                        <td>34.7</td>
                                        <td>29.4 </td>
                                        <td>41.6</td>
                                        <td>11.8</td>
                                        <td>13.2</td>
                                        <td>37.7</td>
                                        <td>37.9</td>
                                        <td>28.4 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Platypus</td>
                                        <td>Llama-1</td>
                                        <td>Platypus</td>
                                        <td>37.8</td>
                                        <td>10.1</td>
                                        <td>27.9</td>
                                        <td>40.5</td>
                                        <td>29.1 </td>
                                        <td>51.7</td>
                                        <td>13.8</td>
                                        <td>13.6</td>
                                        <td>38.6</td>
                                        <td>41</td>
                                        <td>31.7 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Tulu</td>
                                        <td>Llama-2</td>
                                        <td>Tulu</td>
                                        <td>51</td>
                                        <td>10.8</td>
                                        <td>25.5</td>
                                        <td>43.4</td>
                                        <td>32.6 </td>
                                        <td>59</td>
                                        <td>10.7</td>
                                        <td>10.3</td>
                                        <td>31.3</td>
                                        <td>39.8</td>
                                        <td>30.2 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTHc</td>
                                        <td>Code-Llama</td>
                                        <td>MathInstruct</td>
                                        <td>72.3</td>
                                        <td>46.8</td>
                                        <td>50.8</td>
                                        <td>59.6</td>
                                        <td>57.3 </td>
                                        <td>84</td>
                                        <td>64.7</td>
                                        <td>50.6</td>
                                        <td>51.8</td>
                                        <td>50.2</td>
                                        <td>60.3 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>$\Delta$</td>
                                        <td></td>
                                        <td></td>
                                        <td>+16</td>
                                        <td>+22</td>
                                        <td>+17</td>
                                        <td>+16</td>
                                        <td>+25 </td>
                                        <td>+15</td>
                                        <td>+30</td>
                                        <td>+37</td>
                                        <td>+13</td>
                                        <td>+9</td>
                                        <td>+29 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr class="th">
                                        <td id="65_70B" colspan="14" style="text-align: center; font-weight: bold;">65-70B Parameter Model</td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-1</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>50.9</td>
                                        <td>10.6</td>
                                        <td>35</td>
                                        <td>50.2</td>
                                        <td>36.6 </td>
                                        <td>55.3</td>
                                        <td>14.2</td>
                                        <td>15.2</td>
                                        <td>37.4</td>
                                        <td>44.1</td>
                                        <td>33.2 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-2</td>
                                        <td>-</td>
                                        <td>No</td>
                                        <td>56.8</td>
                                        <td>13.5</td>
                                        <td>40.9</td>
                                        <td>50.4</td>
                                        <td>40.4 </td>
                                        <td>63.8</td>
                                        <td>20.5</td>
                                        <td>14</td>
                                        <td>51.3</td>
                                        <td>47.1</td>
                                        <td>39.3 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Llama-2-Chat</td>
                                        <td>Llama-2</td>
                                        <td>No</td>
                                        <td>54.9</td>
                                        <td>18.6</td>
                                        <td>37</td>
                                        <td>51.6</td>
                                        <td>40.5 </td>
                                        <td>71.5</td>
                                        <td>19.2</td>
                                        <td>21.7</td>
                                        <td>44.1</td>
                                        <td>46.9</td>
                                        <td>40.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Guanaco</td>
                                        <td>Llama-2</td>
                                        <td>No</td>
                                        <td>59.2</td>
                                        <td>4.1</td>
                                        <td>45.2</td>
                                        <td>53.5</td>
                                        <td>40.5 </td>
                                        <td>66.8</td>
                                        <td>17.8</td>
                                        <td>20.2</td>
                                        <td>50</td>
                                        <td>47.3</td>
                                        <td>40.4 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>WizardMath</td>
                                        <td>Llama-2</td>
                                        <td>GSM8K+MATH</td>
                                        <td>81.6</td>
                                        <td>22.7</td>
                                        <td>20</td>
                                        <td>48.9</td>
                                        <td>43.3 </td>
                                        <td>71.8</td>
                                        <td>17.1</td>
                                        <td>37.9</td>
                                        <td>13.2</td>
                                        <td>27.4</td>
                                        <td>33.4 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>Platypus</td>
                                        <td>Llama-2</td>
                                        <td>Platypus</td>
                                        <td>70.6</td>
                                        <td>18.6</td>
                                        <td>51.2</td>
                                        <td>55.4</td>
                                        <td>48.9 </td>
                                        <td>51.8</td>
                                        <td>26.3</td>
                                        <td>21.7</td>
                                        <td>55.9</td>
                                        <td>52.5</td>
                                        <td>41.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>MAmmoTH</td>
                                        <td>Llama-2</td>
                                        <td>MathInstruct</td>
                                        <td>76.7</td>
                                        <td>44.2</td>
                                        <td>61.4</td>
                                        <td>64.3</td>
                                        <td>61.7 </td>
                                        <td>81.7</td>
                                        <td>55.3</td>
                                        <td>45.3</td>
                                        <td>58.6</td>
                                        <td>52.3</td>
                                        <td>58.6 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                                    <tr>
                                        <td>$\Delta$</td>
                                        <td></td>
                                        <td></td>
                                        <td>-5</td>
                                        <td>+22</td>
                                        <td>+10</td>
                                        <td>+9</td>
                                        <td>+13 </td>
                                        <td>+10</td>
                                        <td>+29</td>
                                        <td>+8</td>
                                        <td>+3</td>
                                        <td>+0</td>
                                        <td>+17 </td>
                                    </tr>
                                    <tr>
                                    </tr>
                        </div>
                        </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>
        </div>
    </section> -->



    <!-- BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">Reference</h2>
            Please kindly cite our paper if you use our code, data, models or results:
            <br><br>
            <pre><code>@article{Jiang2023TIGERScoreTB,
    title={TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks},
    author={Dongfu Jiang and Yishan Li and Ge Zhang and Wenhao Huang and Bill Yuchen Lin and Wenhu Chen},
    journal={arXiv preprint arXiv:2310.00752},
    year={2023}
}
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a>                            project page. You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                                target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>
<style>
    .buttonGroup {
        text-align: center;
    }
    
    .buttonGroup>button {
        padding: 15px;
        color: white;
        background-color: #363636;
        border-radius: 5px;
    }
    
    .buttonGroup>button:hover {
        box-shadow: 5px;
    }
</style>

</html>
