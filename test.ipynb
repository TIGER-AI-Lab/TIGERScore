{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 4.17MB [00:00, 50.2MB/s]                   \n",
      "Downloading data: 750kB [00:00, 41.9MB/s]                   1.49it/s]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 2732.45it/s]\n",
      "Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 46397.66 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 47263.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ManualDownloadError",
     "evalue": "                  The dataset newsroom with config default requires manual data.\n                  Please follow the manual download instructions:\n                     You should download the dataset from https://lil.nlp.cornell.edu/newsroom/download/index.html\nThe webpage requires registration.\nTo unzip the .tar file run `tar -zxvf complete.tar`. To unzip the .gz files\nrun `gunzip train.json.gz` , ...\nAfter downloading, please put the files under the following names\ndev.jsonl, test.jsonl and train.jsonl in a dir of your choice,\nwhich will be used as a manual_dir, e.g. `~/.manual_dirs/newsroom`\nNewsroom can then be loaded via:\n`datasets.load_dataset(\"newsroom\", data_dir=\"~/.manual_dirs/newsroom\")`.\n\n                  Manual data can be loaded with:\n                   datasets.load_dataset(\"newsroom\", data_dir=\"<path/to/manual/data>\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mManualDownloadError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/dongfu/WorkSpace/TIGERScore/test.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdarth/home/dongfu/WorkSpace/TIGERScore/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdarth/home/dongfu/WorkSpace/TIGERScore/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mnewsroom\u001b[39;49m\u001b[39m\"\u001b[39;49m, streaming\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tigerscore/lib/python3.9/site-packages/datasets/load.py:2146\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2145\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n\u001b[0;32m-> 2146\u001b[0m     \u001b[39mreturn\u001b[39;00m builder_instance\u001b[39m.\u001b[39;49mas_streaming_dataset(split\u001b[39m=\u001b[39;49msplit)\n\u001b[1;32m   2148\u001b[0m \u001b[39m# Some datasets are already processed on the HF google storage\u001b[39;00m\n\u001b[1;32m   2149\u001b[0m \u001b[39m# Don't try downloading from Google storage for the packaged datasets as text, json, csv or pandas\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n",
      "File \u001b[0;32m~/miniconda3/envs/tigerscore/lib/python3.9/site-packages/datasets/builder.py:1328\u001b[0m, in \u001b[0;36mDatasetBuilder.as_streaming_dataset\u001b[0;34m(self, split, base_path)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading a streaming dataset cached in a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not supported yet.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1322\u001b[0m dl_manager \u001b[39m=\u001b[39m StreamingDownloadManager(\n\u001b[1;32m   1323\u001b[0m     base_path\u001b[39m=\u001b[39mbase_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_path,\n\u001b[1;32m   1324\u001b[0m     download_config\u001b[39m=\u001b[39mDownloadConfig(token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken, storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options),\n\u001b[1;32m   1325\u001b[0m     dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name,\n\u001b[1;32m   1326\u001b[0m     data_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_dir,\n\u001b[1;32m   1327\u001b[0m )\n\u001b[0;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_manual_download(dl_manager)\n\u001b[1;32m   1329\u001b[0m splits_generators \u001b[39m=\u001b[39m {sg\u001b[39m.\u001b[39mname: sg \u001b[39mfor\u001b[39;00m sg \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_generators(dl_manager)}\n\u001b[1;32m   1330\u001b[0m \u001b[39m# By default, return all splits\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tigerscore/lib/python3.9/site-packages/datasets/builder.py:977\u001b[0m, in \u001b[0;36mDatasetBuilder._check_manual_download\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_manual_download\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n\u001b[1;32m    976\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mmanual_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m         \u001b[39mraise\u001b[39;00m ManualDownloadError(\n\u001b[1;32m    978\u001b[0m             textwrap\u001b[39m.\u001b[39mdedent(\n\u001b[1;32m    979\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39m                The dataset \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m with config \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m requires manual data.\u001b[39m\n\u001b[1;32m    981\u001b[0m \u001b[39m                Please follow the manual download instructions:\u001b[39m\n\u001b[1;32m    982\u001b[0m \u001b[39m                 \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions\u001b[39m}\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m                Manual data can be loaded with:\u001b[39m\n\u001b[1;32m    984\u001b[0m \u001b[39m                 datasets.load_dataset(\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, data_dir=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<path/to/manual/data>\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    985\u001b[0m             )\n\u001b[1;32m    986\u001b[0m         )\n",
      "\u001b[0;31mManualDownloadError\u001b[0m:                   The dataset newsroom with config default requires manual data.\n                  Please follow the manual download instructions:\n                     You should download the dataset from https://lil.nlp.cornell.edu/newsroom/download/index.html\nThe webpage requires registration.\nTo unzip the .tar file run `tar -zxvf complete.tar`. To unzip the .gz files\nrun `gunzip train.json.gz` , ...\nAfter downloading, please put the files under the following names\ndev.jsonl, test.jsonl and train.jsonl in a dir of your choice,\nwhich will be used as a manual_dir, e.g. `~/.manual_dirs/newsroom`\nNewsroom can then be loaded via:\n`datasets.load_dataset(\"newsroom\", data_dir=\"~/.manual_dirs/newsroom\")`.\n\n                  Manual data can be loaded with:\n                   datasets.load_dataset(\"newsroom\", data_dir=\"<path/to/manual/data>\")"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"newsroom\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 7473\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tigerscore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
