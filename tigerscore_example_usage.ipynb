{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.0, -0.0, -5.0, -0.0, -1.0, -6.0, -0.0, -1.0, -1.0, -1.0]\n",
      "{'num_errors': 2, 'score': -5.0, 'errors': {'error_0': {'location': 'the future head of the European Championships', 'aspect': 'Accuracy', 'explanation': \"The model incorrectly translates 'EM-Cheforganisator' as 'head of the European Championships'. The correct translation should be 'head organizer of the European Football Championship'. This error changes the meaning of the sentence.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'is to participate in the DFB Presidency', 'aspect': 'Terminology', 'explanation': \"The model uses 'participate in' instead of 'work for' when translating 'mitarbeiten' in the context of 'DFB-Pr채sidium'. While 'participate in' is not incorrect, 'work for' is a more accurate translation in this context. This is a minor error as it does not significantly change the meaning of the sentence.\", 'severity': 'Minor', 'score_reduction': '1'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Der k체nftige EM-Cheforganisator Philipp Lahm soll laut Grindel im DFB-Pr채sidium mitarbeiten.\\nModel-generated Output: According to Grindel, the future head of the European Championships, Philipp Lahm, is to participate in the DFB Presidency.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 5.\\nError location 1: the future head of the European Championships\\nError aspect 1: Accuracy\\nExplanation 1: The model incorrectly translates \\'EM-Cheforganisator\\' as \\'head of the European Championships\\'. The correct translation should be \\'head organizer of the European Football Championship\\'. This error changes the meaning of the sentence.\\nSeverity 1: Major\\nScore reduction 1: 4\\nError location 2: is to participate in the DFB Presidency\\nError aspect 2: Terminology\\nExplanation 2: The model uses \\'participate in\\' instead of \\'work for\\' when translating \\'mitarbeiten\\' in the context of \\'DFB-Pr채sidium\\'. While \\'participate in\\' is not incorrect, \\'work for\\' is a more accurate translation in this context. This is a minor error as it does not significantly change the meaning of the sentence.\\nSeverity 2: Minor\\nScore reduction 2: 1'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from datasets import load_dataset\n",
    "from tigerscore import TIGERScorer\n",
    "# set up scorer\n",
    "scorer = TIGERScorer(model_size=\"7b\", quantized=True)\n",
    "# load the dataset\n",
    "dataset = load_dataset(\"TIGER-Lab/MetricInstruct\")\n",
    "num_few_examples = 10\n",
    "tasks = dataset[\"train_mix\"]['task'][0:num_few_examples]\n",
    "insts = dataset[\"train_mix\"]['instruction'][0:num_few_examples]\n",
    "input_contexts = dataset[\"train_mix\"]['input_context'][0:num_few_examples]\n",
    "hypo_output = dataset[\"train_mix\"]['hypo_output'][0:num_few_examples]\n",
    "# scoring\n",
    "results = scorer.score(tasks, insts, input_contexts, hypo_output, batch_size=8)\n",
    "scores = [result[\"score\"] for result in results] # List of float scores\n",
    "print(scores)\n",
    "print(results[0]) # associated explanation texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continual_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
