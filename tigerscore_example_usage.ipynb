{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongfu/miniconda3/envs/tigerscore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading config.json: 100%|██████████| 662/662 [00:00<00:00, 136kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-26 18:00:16,615] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)fetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 5.65MB/s]\n",
      "Downloading (…)of-00003.safetensors: 100%|██████████| 4.94G/4.94G [01:22<00:00, 59.7MB/s]\n",
      "Downloading (…)of-00003.safetensors: 100%|██████████| 4.95G/4.95G [01:29<00:00, 55.5MB/s]\n",
      "Downloading (…)of-00003.safetensors: 100%|██████████| 3.59G/3.59G [01:03<00:00, 56.5MB/s]\n",
      "Downloading shards: 100%|██████████| 3/3 [03:56<00:00, 78.83s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Downloading generation_config.json: 100%|██████████| 183/183 [00:00<00:00, 49.3kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 1.11k/1.11k [00:00<00:00, 1.25MB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 14.6MB/s]\n",
      "Downloading added_tokens.json: 100%|██████████| 21.0/21.0 [00:00<00:00, 17.1kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 552/552 [00:00<00:00, 537kB/s]\n",
      "TIGERScore Batch Scoring: 100%|██████████| 2/2 [00:43<00:00, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0, -0.0, -6.0, -0.0, -5.0, -6.0, -1.0, -1.0, -1.0, -1.0]\n",
      "{'num_errors': 1, 'score': -0.0, 'errors': {'error_0': {'location': 'participate in the DFB Presidency', 'aspect': 'Accuracy', 'explanation': \"The verb 'participate' is not the most accurate translation of 'mitarbeiten' in this context. A more accurate translation would be 'work with'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a given instruction.\\nInstruction: \\nTranslate the following text from German to English.\\nDer künftige EM-Cheforganisator Philipp Lahm soll laut Grindel im DFB-Präsidium mitarbeiten.\\n\\nModel-generated Output: \\nAccording to Grindel, the future head of the European Championships, Philipp Lahm, is to participate in the DFB Presidency.\\n\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output: The model-generated output contains 1 errors, with a total score reduction of 0.5.\\nError location 1: participate in the DFB Presidency\\nError aspect 1: Accuracy\\nExplanation 1: The verb \\'participate\\' is not the most accurate translation of \\'mitarbeiten\\' in this context. A more accurate translation would be \\'work with\\'.\\nSeverity 1: Minor\\nScore reduction 1: 0.5'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from datasets import load_dataset\n",
    "from tigerscore import TIGERScorer\n",
    "# set up scorer\n",
    "scorer = TIGERScorer(model_name=\"TIGER-Lab/TIGERScore-7B-V1.2\", quantized=False)\n",
    "# load the dataset\n",
    "dataset = load_dataset(\"TIGER-Lab/MetricInstruct\")\n",
    "num_few_examples = 10\n",
    "tasks = dataset[\"train_mix\"]['task'][0:num_few_examples]\n",
    "insts = dataset[\"train_mix\"]['instruction'][0:num_few_examples]\n",
    "input_contexts = dataset[\"train_mix\"]['input_context'][0:num_few_examples]\n",
    "hypo_output = dataset[\"train_mix\"]['hypo_output'][0:num_few_examples]\n",
    "# scoring\n",
    "results = scorer.score(tasks, insts, input_contexts, hypo_output, batch_size=8)\n",
    "scores = [result[\"score\"] for result in results] # List of float scores\n",
    "print(scores)\n",
    "print(results[0]) # associated explanation texts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continual_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
