{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongfu/miniconda3/envs/tigerscore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "TIGERScore Batch Scoring: 100%|██████████| 2/2 [01:00<00:00, 30.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'num_errors': 2, 'score': -5.0, 'errors': {'error_0': {'location': 'the future head of the European Championships', 'aspect': 'Accuracy', 'explanation': \"The model incorrectly translates 'EM-Cheforganisator' as 'head of the European Championships'. The correct translation should be 'head organizer of the European Football Championship'. This error changes the meaning of the sentence.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'is to participate in the DFB Presidency', 'aspect': 'Terminology', 'explanation': \"The model uses 'participate in' instead of 'work for' when translating 'mitarbeiten' in the context of 'DFB-Präsidium'. While 'participate in' is not incorrect, 'work for' is a more accurate translation in this context. This is a minor error as it does not significantly change the meaning of the sentence.\", 'severity': 'Minor', 'score_reduction': '1'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Der künftige EM-Cheforganisator Philipp Lahm soll laut Grindel im DFB-Präsidium mitarbeiten.\\nModel-generated Output: According to Grindel, the future head of the European Championships, Philipp Lahm, is to participate in the DFB Presidency.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 5.\\nError location 1: the future head of the European Championships\\nError aspect 1: Accuracy\\nExplanation 1: The model incorrectly translates \\'EM-Cheforganisator\\' as \\'head of the European Championships\\'. The correct translation should be \\'head organizer of the European Football Championship\\'. This error changes the meaning of the sentence.\\nSeverity 1: Major\\nScore reduction 1: 4\\nError location 2: is to participate in the DFB Presidency\\nError aspect 2: Terminology\\nExplanation 2: The model uses \\'participate in\\' instead of \\'work for\\' when translating \\'mitarbeiten\\' in the context of \\'DFB-Präsidium\\'. While \\'participate in\\' is not incorrect, \\'work for\\' is a more accurate translation in this context. This is a minor error as it does not significantly change the meaning of the sentence.\\nSeverity 2: Minor\\nScore reduction 2: 1'}, {'num_errors': 1, 'score': -0.0, 'errors': {'error_0': {'location': 'base', 'aspect': 'Terminology', 'explanation': \"The term 'base' is used instead of 'database'. Although both terms can be used interchangeably in this context, 'database' is a more accurate translation of the original Russian word 'базы'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Он пояснил, что для создания такой базы потребуется внести поправки в законодательство.\\nModel-generated Output: He explained that the creation of such a base would require amendments to the legislation.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 1 errors, with a total score reduction of 0.5.\\nError location 1: base\\nError aspect 1: Terminology\\nExplanation 1: The term \\'base\\' is used instead of \\'database\\'. Although both terms can be used interchangeably in this context, \\'database\\' is a more accurate translation of the original Russian word \\'базы\\'.\\nSeverity 1: Minor\\nScore reduction 1: 0.5'}, {'num_errors': 2, 'score': -5.0, 'errors': {'error_0': {'location': 'doctors and doctors', 'aspect': 'Accuracy', 'explanation': \"The model incorrectly repeats the word 'doctors' instead of mentioning the specific doctors and physiotherapist mentioned in the source text. This is a major error as it changes the meaning of the sentence. The correct translation should be 'thanks to the doctors and the physiotherapist'.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'that they put on their feet', 'aspect': 'Fluency', 'explanation': \"The phrase 'that they put on their feet' is a bit awkward in English. A more natural way to express this would be 'who put me on my feet'. This is a minor error as it doesn't change the overall meaning of the sentence, but it does affect the fluency.\", 'severity': 'Minor', 'score_reduction': '1'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Но еще раз повторюсь, спасибо физиотерапевту и докторам, что поставили на ноги.\\nModel-generated Output: But once again I repeat, thanks to the doctors and doctors that they put on their feet.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 5.\\nError location 1: doctors and doctors\\nError aspect 1: Accuracy\\nExplanation 1: The model incorrectly repeats the word \\'doctors\\' instead of mentioning the specific doctors and physiotherapist mentioned in the source text. This is a major error as it changes the meaning of the sentence. The correct translation should be \\'thanks to the doctors and the physiotherapist\\'.\\nSeverity 1: Major\\nScore reduction 1: 4\\nError location 2: that they put on their feet\\nError aspect 2: Fluency\\nExplanation 2: The phrase \\'that they put on their feet\\' is a bit awkward in English. A more natural way to express this would be \\'who put me on my feet\\'. This is a minor error as it doesn\\'t change the overall meaning of the sentence, but it does affect the fluency.\\nSeverity 2: Minor\\nScore reduction 2: 1'}, {'num_errors': 0, 'score': -0.0, 'errors': {}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Trump and Modi would do very well to keep Gandhi\\'s advice in mind, 150 years after his birth.\\nModel-generated Output: Trump und Modi täten sehr gut daran, Gandhis Rat 150 Jahre nach seiner Geburt im Auge zu behalten.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 0 errors, with a total score reduction of 0.'}, {'num_errors': 2, 'score': -1.0, 'errors': {'error_0': {'location': 'Kontrollen auf Kaffeebohnen', 'aspect': 'Fluency', 'explanation': \"The phrase 'Kontrollen auf Kaffeebohnen' is grammatically correct but sounds a bit awkward in German. A more natural way to express this would be 'Kontrollen der Kaffeebohnen'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'Unkrautvernichter Angst', 'aspect': 'Terminology', 'explanation': \"The phrase 'Unkrautvernichter Angst' is not a common way to express the fear of herbicides in German. A more accurate translation would be 'Unkrautvernichtungsmittel-Angst'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Nestle tightens controls on coffee beans after weedkiller scare\\nModel-generated Output: Nestle verschärft Kontrollen auf Kaffeebohnen nach Unkrautvernichter Angst\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 1.0.\\nError location 1: Kontrollen auf Kaffeebohnen\\nError aspect 1: Fluency\\nExplanation 1: The phrase \\'Kontrollen auf Kaffeebohnen\\' is grammatically correct but sounds a bit awkward in German. A more natural way to express this would be \\'Kontrollen der Kaffeebohnen\\'.\\nSeverity 1: Minor\\nScore reduction 1: 0.5\\nError location 2: Unkrautvernichter Angst\\nError aspect 2: Terminology\\nExplanation 2: The phrase \\'Unkrautvernichter Angst\\' is not a common way to express the fear of herbicides in German. A more accurate translation would be \\'Unkrautvernichtungsmittel-Angst\\'.\\nSeverity 2: Minor\\nScore reduction 2: 0.5'}, {'num_errors': 3, 'score': -6.0, 'errors': {'error_0': {'location': 'following the Russian Olympic team', 'aspect': 'Accuracy', 'explanation': \"The output incorrectly states that the 'following Russian Olympic team' will have only four gymnasts, when the source text refers to the 'next Olympic team' which could be any country. The correct translation should be 'the next Olympic team'.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'Martha karolyi', 'aspect': 'Terminology', 'explanation': \"The coach's name is incorrectly translated as 'Martha karolyi' instead of 'Márta Karády'. This is a minor error as it is a slight misspelling of the coach's name, but it is still incorrect. The correct translation should be 'Márta Karády'.\", 'severity': 'Minor', 'score_reduction': '1'}, 'error_2': {'location': 'final five', 'aspect': 'Style Matching', 'explanation': \"The phrase 'final five' is not incorrect, but it is less commonly used in English. A more common phrase would be 'final four' as it is more appropriate for the context of the source text. This is a minor error as it does not significantly impact the overall meaning of the sentence.\", 'severity': 'Minor', 'score_reduction': '1'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: Они являются \"финальной пятеркой\", потому что следующая олимпийская сборная по гимнастике будет иметь только четыре гимнаста в команде, и это последний год тренерства Марты Кароли.\\nModel-generated Output: They are the \"final five\", because following the Russian Olympic team will have only four gymnast in the team, and this is the last year coach Martha karolyi.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 3 errors, with a total score reduction of 6.\\nError location 1: following the Russian Olympic team\\nError aspect 1: Accuracy\\nExplanation 1: The output incorrectly states that the \\'following Russian Olympic team\\' will have only four gymnasts, when the source text refers to the \\'next Olympic team\\' which could be any country. The correct translation should be \\'the next Olympic team\\'.\\nSeverity 1: Major\\nScore reduction 1: 4\\nError location 2: Martha karolyi\\nError aspect 2: Terminology\\nExplanation 2: The coach\\'s name is incorrectly translated as \\'Martha karolyi\\' instead of \\'Márta Karády\\'. This is a minor error as it is a slight misspelling of the coach\\'s name, but it is still incorrect. The correct translation should be \\'Márta Karády\\'.\\nSeverity 2: Minor\\nScore reduction 2: 1\\nError location 3: final five\\nError aspect 3: Style Matching\\nExplanation 3: The phrase \\'final five\\' is not incorrect, but it is less commonly used in English. A more common phrase would be \\'final four\\' as it is more appropriate for the context of the source text. This is a minor error as it does not significantly impact the overall meaning of the sentence.\\nSeverity 3: Minor\\nScore reduction 3: 1'}, {'num_errors': 0, 'score': -0.0, 'errors': {}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: В ходе небольшого скетча актер сыграл Кавано на слушаниях в сенате по обвинению в изнасиловании.\\nModel-generated Output: In a small sketch, the actor played Kavanaugh at a Senate hearing on charges of rape.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 0 errors, with a total score reduction of 0.'}, {'num_errors': 2, 'score': -1.0, 'errors': {'error_0': {'location': 'the Tianshan District Federation of Trade Unions of Urumqi City', 'aspect': 'Fluency', 'explanation': \"The phrase 'the Tianshan District Federation of Trade Unions of Urumqi City' is a bit redundant and verbose. A more concise and accurate translation would be 'the Tianshan District Federation of Trade Unions in Urumqi'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'epidemic prevention and control living materials', 'aspect': 'Fluency', 'explanation': \"The phrase 'epidemic prevention and control living materials' is a bit awkward and verbose. A more concise and accurate translation would be 'living materials for epidemic prevention and control'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: 近日，乌鲁木齐市天山区总工会慰问组一行，将一批急需的疫情防控生活物资送到了12个隔离点的工作人员手中。\\nModel-generated Output: Recently, the condolence group of the Tianshan District Federation of Trade Unions of Urumqi City sent a batch of urgently needed epidemic prevention and control living materials to the staff of 12 isolation points.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 1.0.\\nError location 1: the Tianshan District Federation of Trade Unions of Urumqi City\\nError aspect 1: Fluency\\nExplanation 1: The phrase \\'the Tianshan District Federation of Trade Unions of Urumqi City\\' is a bit redundant and verbose. A more concise and accurate translation would be \\'the Tianshan District Federation of Trade Unions in Urumqi\\'.\\nSeverity 1: Minor\\nScore reduction 1: 0.5\\nError location 2: epidemic prevention and control living materials\\nError aspect 2: Fluency\\nExplanation 2: The phrase \\'epidemic prevention and control living materials\\' is a bit awkward and verbose. A more concise and accurate translation would be \\'living materials for epidemic prevention and control\\'.\\nSeverity 2: Minor\\nScore reduction 2: 0.5'}, {'num_errors': 2, 'score': -1.0, 'errors': {'error_0': {'location': 'In doing so', 'aspect': 'Style Matching', 'explanation': \"The phrase 'In doing so' is not incorrect, but it is less natural in this context. A more natural translation would be 'Meanwhile' or 'At the same time'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'will drag them down as incompetence', 'aspect': 'Accuracy', 'explanation': \"The phrase 'will drag them down as incompetence' is not a direct translation of 'истолкуют их как некомпетентность'. A more accurate translation would be 'will interpret them as incompetence'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: При этом Трамп попросил не воспринимать его слова буквально и предупредил, что американские СМИ истолкуют их как некомпетентность.\\nModel-generated Output: In doing so, Trump asked not to take his words literally and warned that the American media will drag them down as incompetence.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 2 errors, with a total score reduction of 1.0.\\nError location 1: In doing so\\nError aspect 1: Style Matching\\nExplanation 1: The phrase \\'In doing so\\' is not incorrect, but it is less natural in this context. A more natural translation would be \\'Meanwhile\\' or \\'At the same time\\'.\\nSeverity 1: Minor\\nScore reduction 1: 0.5\\nError location 2: will drag them down as incompetence\\nError aspect 2: Accuracy\\nExplanation 2: The phrase \\'will drag them down as incompetence\\' is not a direct translation of \\'истолкуют их как некомпетентность\\'. A more accurate translation would be \\'will interpret them as incompetence\\'.\\nSeverity 2: Minor\\nScore reduction 2: 0.5'}, {'num_errors': 3, 'score': -1.0, 'errors': {'error_0': {'location': 'unempfindlich', 'aspect': 'Terminology', 'explanation': \"The term 'unempfindlich' is not incorrect, but 'immun' would be a more accurate translation for 'impervious' in this context.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'Wahlblöcke', 'aspect': 'Terminology', 'explanation': \"The term 'Wahlblöcke' is not incorrect, but 'Wählergruppen' or 'Wählerblöcke' would be more accurate translations for 'voting blocs'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_2': {'location': 'schüren und sozialen Antagonismus', 'aspect': 'Fluency', 'explanation': \"The phrase 'schüren und sozialen Antagonismus' is not incorrect, but 'schüren und die soziale Antagonismus' would be a more accurate translation for 'fomenting division and social antagonism'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}, 'raw_output': 'You are evaluating errors in a model-generated output for a(an) translation task.\\nTask instruction: You are evaluating errors in a model-generated output for a(an) translation task.\\nSource: But President Donald Trump and Indian Prime Minister Narendra Modi, who triumphantly addressed a joint mega-rally in Houston recently, seem to be impervious to Gandhi\\'s ideas, despite paying lip service to him at the event. Both are right-wing populists who have ruled with scant compassion or tolerance, successfully mobilizing whites and Hindus in their respective countries as voting blocs, and fomenting division and social antagonism.\\nModel-generated Output: Doch Präsident Donald Trump und der indische Premierminister Narendra Modi, die vor kurzem triumphierend eine gemeinsame Mega-Kundgebung in Houston ansprachen, scheinen für Gandhis Ideen unempfindlich zu sein, obwohl sie ihm bei der Veranstaltung Lippenbekenntnisse ablegten. Beide sind Rechtspopulisten, die mit wenig Mitgefühl oder Toleranz regiert haben, Weiße und Hindus in ihren jeweiligen Ländern erfolgreich als Wahlblöcke mobilisieren und Spaltung und sozialen Antagonismus schüren.\\n\\nBased on the given task instruction and source, identify errors in this model-generated output.\\nFor each error you give in the response, please also elaborate the following information:\\n- error location (the words that are wrong in the output)\\n- error aspect it belongs to.\\n- explanation why it\\'s an error, and the correction suggestions.\\n- severity of the error (\"Major\" or \"Minor\"). \\n- reduction of score (between 0.5 and 5 given the severity of the error)\\n\\nYour evaluation output:\\nThe model-generated output contains 3 errors, with a total score reduction of 1.5.\\nError location 1: unempfindlich\\nError aspect 1: Terminology\\nExplanation 1: The term \\'unempfindlich\\' is not incorrect, but \\'immun\\' would be a more accurate translation for \\'impervious\\' in this context.\\nSeverity 1: Minor\\nScore reduction 1: 0.5\\nError location 2: Wahlblöcke\\nError aspect 2: Terminology\\nExplanation 2: The term \\'Wahlblöcke\\' is not incorrect, but \\'Wählergruppen\\' or \\'Wählerblöcke\\' would be more accurate translations for \\'voting blocs\\'.\\nSeverity 2: Minor\\nScore reduction 2: 0.5\\nError location 3: schüren und sozialen Antagonismus\\nError aspect 3: Fluency\\nExplanation 3: The phrase \\'schüren und sozialen Antagonismus\\' is not incorrect, but \\'schüren und die soziale Antagonismus\\' would be a more accurate translation for \\'fomenting division and social antagonism\\'.\\nSeverity 3: Minor\\nScore reduction 3: 0.5'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from datasets import load_dataset\n",
    "from tigerscore import TIGERScorer\n",
    "scorer = TIGERScorer(model_size=\"7b\", quantized=True)\n",
    "dataset = load_dataset(\"TIGER-Lab/MetricInstruct\")\n",
    "num_few_examples = 10\n",
    "tasks = dataset[\"train_mix\"]['task'][0:num_few_examples]\n",
    "insts = dataset[\"train_mix\"]['instruction'][0:num_few_examples]\n",
    "input_contexts = dataset[\"train_mix\"]['input_context'][0:num_few_examples]\n",
    "hypo_output = dataset[\"train_mix\"]['hypo_output'][0:num_few_examples]\n",
    "results = scorer.score(tasks, insts, input_contexts, hypo_output)\n",
    "scores = [result[\"score\"] for result in results]\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_0': {'location': 'the future head of the European Championships', 'aspect': 'Accuracy', 'explanation': \"The model incorrectly translates 'EM-Cheforganisator' as 'head of the European Championships'. The correct translation should be 'head organizer of the European Football Championship'. This error changes the meaning of the sentence.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'is to participate in the DFB Presidency', 'aspect': 'Terminology', 'explanation': \"The model uses 'participate in the DFB Presidency' instead of 'work for the DFB Presidential Board'. While 'participate' is not incorrect, 'work for' is a more accurate translation of 'mitarbeiten' in this context, as it implies a more active role than 'participate'. This error does not significantly change the meaning of the sentence.\", 'severity': 'Minor', 'score_reduction': '1'}}\n",
      "##################################################\n",
      "{'error_0': {'location': 'base', 'aspect': 'Terminology', 'explanation': \"The term 'base' is used instead of 'database'. Although both terms can be used interchangeably in this context, 'database' is a more accurate translation of the original Russian word 'базы'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}\n",
      "##################################################\n",
      "{'error_0': {'location': 'doctors and doctors', 'aspect': 'Accuracy', 'explanation': \"The model incorrectly repeats the word 'doctors' ('thanks to the doctors and doctors'). The correct translation should be 'thanks to the physiotherapist and doctors'. This error significantly impacts the meaning of the sentence.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'that they put on their feet', 'aspect': 'Fluency', 'explanation': \"The phrase 'that they put on their feet' is a bit awkward in English. A more natural way to express this would be 'who put me on my feet'. This is a minor error as it doesn't significantly impact the overall meaning of the sentence, but it does affect the fluency.\", 'severity': 'Minor', 'score_reduction': '1'}}\n",
      "##################################################\n",
      "{}\n",
      "##################################################\n",
      "{'error_0': {'location': 'Kontrollen auf Kaffeebohnen', 'aspect': 'Fluency', 'explanation': \"The phrase 'Kontrollen auf Kaffeebohnen' is not incorrect, but it is less natural in German. A more fluent translation would be 'Kontrollen der Kaffeebohnen'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}\n",
      "##################################################\n",
      "{'error_0': {'location': 'following the Russian Olympic team', 'aspect': 'Accuracy', 'explanation': \"The output incorrectly states that the 'Russian Olympic team' will have only four gymnasts, when the source text refers to the 'next Olympic team' having only four gymnasts. This is a significant error as it changes the meaning of the sentence. The correct translation should be 'next Olympic team'.\", 'severity': 'Major', 'score_reduction': '4'}, 'error_1': {'location': 'Martha karolyi', 'aspect': 'Terminology', 'explanation': \"The coach's name is incorrectly translated as 'Martha karolyi' instead of 'Marta Karolyi'. This is a minor error as it is a slight misspelling of the coach's name, but it should still be corrected for accuracy.\", 'severity': 'Minor', 'score_reduction': '1'}, 'error_2': {'location': 'final five', 'aspect': 'Style Matching', 'explanation': \"The phrase 'final five' is not as commonly used in Russian as 'final four' in the context of sports. This is a minor error as it does not significantly impact the overall meaning of the sentence, but it would be better to use 'final four' for a more natural translation.\", 'severity': 'Minor', 'score_reduction': '1'}}\n",
      "##################################################\n",
      "{}\n",
      "##################################################\n",
      "{'error_0': {'location': 'the Tianshan District Federation of Trade Unions of Urumqi City', 'aspect': 'Fluency', 'explanation': \"The phrase 'the Tianshan District Federation of Trade Unions of Urumqi City' is a bit awkward and verbose. A more natural translation would be 'the Urumqi Tianshan District Federation of Trade Unions'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'epidemic prevention and control living materials', 'aspect': 'Fluency', 'explanation': \"The phrase 'epidemic prevention and control living materials' is also verbose. A more natural translation would be 'living materials for epidemic prevention and control' or 'living materials for pandemic prevention and control'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}\n",
      "##################################################\n",
      "{'error_0': {'location': 'In doing so', 'aspect': 'Style Matching', 'explanation': \"The phrase 'In doing so' is not incorrect, but it is less natural in this context. A more common phrase to use would be 'Meanwhile' or 'At the same time'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'will drag them down as incompetence', 'aspect': 'Accuracy', 'explanation': \"The phrase 'will drag them down as incompetence' is not a direct translation of the original text. The phrase 'истолкуют их как некомпетентность' should be translated as 'will interpret them as incompetence'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}\n",
      "##################################################\n",
      "{'error_0': {'location': 'unempfindlich', 'aspect': 'Terminology', 'explanation': \"The term 'unempfindlich' is not incorrect, but 'immun' would be a more accurate translation for 'impervious' in this context.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_1': {'location': 'Wahlblöcke', 'aspect': 'Terminology', 'explanation': \"The term 'Wahlblöcke' is not incorrect, but 'Wählergruppen' or 'Wählerblöcke' would be more accurate translations for 'voting blocs'.\", 'severity': 'Minor', 'score_reduction': '0.5'}, 'error_2': {'location': 'schüren', 'aspect': 'Terminology', 'explanation': \"The term 'schüren' is not incorrect, but 'schüren' or 'schüren' would be more accurate translations for 'fomenting'.\", 'severity': 'Minor', 'score_reduction': '0.5'}}\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for error in errors:\n",
    "    print(error)\n",
    "    print(\"#####\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train_mix'][0]['errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "list([decode_tigerscore_output(x) for x in tqdm(dataset['train_mix']['errors'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def decode_tigerscore_output(output):\n",
    "    \"\"\"Decode the output of TIGERScore model into structured error explanations.\n",
    "\n",
    "    Args:\n",
    "        output (str):\n",
    "            the output of TIGERScore model.\n",
    "    Returns:\n",
    "        errors (List[Dict]):\n",
    "            structured error explanations for each error in the output.\n",
    "            Each error explanation is a dictionary with the following fields:\n",
    "                - error_location (str): the words that are wrong in the output\n",
    "                - error_aspect (str): the aspect of the error\n",
    "                - error_explanation (str): explanation why it's an error, and the correction suggestions\n",
    "                - error_severity (str): severity of the error (\"Major\" or \"Minor\")\n",
    "                - score_reduction (float): reduction of score (between 0.5 and 5 given the severity of the error)\n",
    "            There can be multiple errors in each input.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    result['num_errors'] = re.search(r\"(?<=The model-generated output contains )\\d+(?= errors)\", output).group(0)\n",
    "    result['score'] = re.search(r\"(?<=, with a total score reduction of )\\d+\", output).group(0)\n",
    "    result['errors'] = {}\n",
    "    error_locations = re.findall(r\"(?<=Error location \\d+: ).*?(?=\\n)\", output)\n",
    "    error_aspects = re.findall(r\"(?<=Error aspect \\d+: ).*?(?=\\n)\", output)\n",
    "    error_explanations = re.findall(r\"(?<=Explanation \\d+: ).*?(?=\\n)\", output)\n",
    "    error_severities = re.findall(r\"(?<=Severity \\d+: ).*?(?=\\n)\", output)\n",
    "    score_reductions = re.findall(r\"(?<=\\nScore reduction \\d+: )(\\d+\\.\\d+|\\d+)\", output)\n",
    "    assert len(error_locations) == len(error_aspects) == len(error_explanations) == len(error_severities) == len(score_reductions), \\\n",
    "        \"The number of errors does not match.\"\n",
    "    for i in range(len(error_locations)):\n",
    "        error = {}\n",
    "        error['location'] = error_locations[i]\n",
    "        error['aspect'] = error_aspects[i]\n",
    "        error['explanation'] = error_explanations[i]\n",
    "        error['severity'] = error_severities[i]\n",
    "        error['score_reduction'] = score_reductions[i]\n",
    "        result['errors'][f\"error_{i}\"] = error\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continual_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
